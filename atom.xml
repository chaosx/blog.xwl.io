<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://blog.xwl.io</id>
    <title>许大仙的博客</title>
    <updated>2021-05-01T18:14:47.185Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://blog.xwl.io"/>
    <link rel="self" href="https://blog.xwl.io/atom.xml"/>
    <subtitle>一个运维人的成长历程</subtitle>
    <logo>https://blog.xwl.io/images/avatar.png</logo>
    <icon>https://blog.xwl.io/favicon.ico</icon>
    <rights>All rights reserved 2021, 许大仙的博客</rights>
    <entry>
        <title type="html"><![CDATA[来自长假第一天的挣扎]]></title>
        <id>https://blog.xwl.io/post/tgfaCQjnt/</id>
        <link href="https://blog.xwl.io/post/tgfaCQjnt/">
        </link>
        <updated>2021-05-01T16:05:44.000Z</updated>
        <content type="html"><![CDATA[<p>夜深了 才会有喷涌而来的灵感 难得的假期就不搬砖写代码了。</p>
<p>无聊的时候也会刷刷微博，看看人生百态，也不管什么假不假的。</p>
<p>放假的日子总是特别无聊，不想出门，不想学习，不想打游戏，似乎什么都不想做。</p>
<p>也罢，让自己安静一会。</p>
<p>时间过的很快，不知不觉也毕业好几年，也接收过很多特点的观点，分享一下我的见解吧</p>
<h2 id="不要用战术的勤奋掩盖战略的懒惰">不要用战术的勤奋掩盖战略的懒惰</h2>
<p>这句话是雷军当年说的，起初听的时候也没什么感觉，当你有的经历之后，却能异常深刻。</p>
<p>道理其实很简单，要多思考，不要盲目的努力，但人的惰性会阻碍我们思考，很多情况下，我们宁愿勤奋到死也不愿思考一次。</p>
<p>知道是一回事，实践又是另一回事，就像之前盛行过的一句话，知道了很多道理，却依然过不好这一生。</p>
<p>在这个知识大爆炸的时代，大多数情况都是看过，之后它就会呆在了你的收藏夹里（别问我怎么知道）。</p>
<p>知识获取的成本真的很低，更多的价值体现在于，如何去筛选优质的内容，应用知识来解决问题的思维。</p>
<p>我遇到过最典型的例子就是，在网上找一个技术知识，网上有无数篇同样内容的文章，仔细一下，文中有好多处错误，也一并复制过去了。</p>
<p>这有何用？</p>
<p>话题有点跑偏了，最后分享一下解决思路：<a href="https://mp.weixin.qq.com/s/1nC-JTy7F1QJgRx5fpOulw">人生每步都对，最后满盘皆输？</a></p>
<h2 id="文凭没那么重要实力最重要">文凭没那么重要，实力最重要</h2>
<p>虽然这句话有一定的道理，但我还是要下个结论，文凭真的很重要！</p>
<p>文凭是门槛，是敲门砖，没有的话很多时候都没办法展现自己的“实力”。</p>
<p>除非你的实力能够达到行业的前20%以上，28定律几乎在任何时候都适用，你的能力真的能强到这种程度，那文凭的作用确实对你来说几乎毫无作用，但我们更多的只是普通人，文凭对绝大多数人来说真的很重要。</p>
<p>学习是一辈子的事，文凭是你的外在，实力则是你的内涵，缺一不可。</p>
<p>试想，如果你外表长的过于丑陋，还会有人想了解你内心的美好吗？</p>
<h2 id="钱是赚出来的不是省出来的">钱是赚出来的不是省出来的</h2>
<p>这句话是对的，也是错的，大多数人都高估了自己的赚钱能力。</p>
<p>我刚毕业的时候，也是对这句话深信不疑，你可以花钱投资自己，用于买书、学习等，提高自己，那没问题，工资就算不高，该有的花费也绝对不能省。</p>
<p>可怕的就是消费主义盛行的今天，你对这句话就需要谨慎对待。比如说，买个ipad当生产力工具、买个kindle每天长通勤的时候看书，这个时候你需要思考一个问题，你真的需要它们吗？</p>
<p>我也曾落入过消费主义陷阱，买了很多看似有用，实则却无用的东西，说不后悔是假的，好在我及时的看透了它</p>
<p>你会说，要有一个挣大钱的心，不要局限于省钱来致富。</p>
<p>好似你花钱多了，就能开阔眼界，提高格局？</p>
<p>总结一句话就是，这句话的应用场景，用来投资自己非常正确，但用来消费大可不必。</p>
<p>或许你可以学习一下理财，感受一下延迟满足的快乐。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[操作系统的上下文切换]]></title>
        <id>https://blog.xwl.io/post/RlIk8BA71/</id>
        <link href="https://blog.xwl.io/post/RlIk8BA71/">
        </link>
        <updated>2021-04-25T15:49:14.000Z</updated>
        <content type="html"><![CDATA[<h2 id="简介">简介</h2>
<p>上下文切换 (context switch)指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换；其实际含义是任务切换, 或者CPU寄存器切换</p>
<p>原因</p>
<ul>
<li>当前正在执行的任务完成，系统的CPU正常调度下一个任务。</li>
<li>当前正在执行的任务遇到I/O等阻塞操作，调度器挂起此任务，继续调度下一个任务。</li>
<li>多个任务并发抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续调度下一个任务。</li>
<li>用户的代码挂起当前任务，比如线程执行sleep方法，让出CPU。</li>
<li>硬件中断。</li>
</ul>
<p>一次系统调用的过程，其实是发生了两次 CPU 上下文切换。（用户态-&gt;内核态-&gt;用户态/同进程内的 CPU 上下文切换）</p>
<h2 id="调度策略">调度策略</h2>
<p>处理器给每个线程分配 CPU 时间片（Time Slice），线程在分配获得的时间片内执行任务，一般为几十毫秒。在这么短的时间内线程互相切换，我们根本感觉不到，所以看上去就好像是同时进行的一样。</p>
<p>就是说，假如同时运行100个线程，CPU为了公平调度，会给每个线程分配时间片，当时间片耗尽之后会立即调度下一个线程（上下文切换）</p>
<h2 id="线程与进程">线程与进程</h2>
<p><strong>概念</strong></p>
<ol>
<li>当进程只有一个线程时，可以认为进程就等于线程</li>
<li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。</li>
<li>线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的</li>
</ol>
<p><strong>上下文切换</strong><br>
前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。</p>
<p>前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据</p>
<h2 id="解释">解释</h2>
<p>就单核系统而言，单位时间cpu能做的事情是固定的，这个上限并不因为使用多线程切换得到提高。</p>
<p>多线程出现的意义，就是为了解决IO和CPU之间速度差的冲突，在IO处理等待的时间，CPU可以去处理其他计算任务。</p>
<p>如果是每个线程一直就是在繁忙的计算，那么多个线程事实上也得不到任何好处，反而因为上下文的切换，要消耗比顺序执行更多的时间。</p>
<p>特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是导致平均负载升高的一个重要因素。</p>
<h2 id="优化">优化</h2>
<ul>
<li>无锁并发编程</li>
<li>控制进程/线程数量</li>
<li>协程，单进程单线程，内部任务切换</li>
</ul>
<p>状态监测</p>
<pre><code>pidstat -w -u 5
  cswch  ：表示每秒自愿上下文切换的次数
  nvcswch：表示每秒非自愿上下文切换的次数
</code></pre>
<p>模拟场景工具</p>
<ul>
<li>stress  ：模拟进程、IO</li>
<li>sysbench：模拟线程数</li>
</ul>
<h2 id="在openresty的场景举例">在OpenResty的场景举例</h2>
<p>推荐配置是worker与CPU保持一致，这里是故意而为之。</p>
<p>由于worker的设计是单进程单线程的，这里我们的例子将模拟使用1个CPU使用2个worker进程</p>
<p><strong>正常的上下文切换</strong></p>
<pre><code>ngx.say(&quot;hello&quot;)
</code></pre>
<p>这句话的意思是输出响应体，如果同时有两个用户进来，worker A和B会争抢CPU资源，假设A抢到了资源，那么B将被挂起，等待A执行完毕之后，CPU将会正常调度下一个任务。</p>
<p><strong>主动的上下文切换</strong></p>
<pre><code>ngx.sleep(0)
</code></pre>
<p>以上操作是用来实现主动让出CPU，使用场景是在CPU密集型的程序段，长时间占用CPU，比如以下代码段</p>
<pre><code>for i=10000000000000,1,-1 
do 
   print(i)
end
</code></pre>
<p><strong>IO阻塞</strong></p>
<pre><code>os.getenv(&quot;SE_UPSTREAMS&quot;)
</code></pre>
<p>假设在access阶段，每个用户访问它都会从系统环境变量中取值，它就会造成阻塞，需要等待它完成之后CPU才会释放。这个过程经历的两次上下文切换（用户态-&gt;内核态-&gt;系统态）。可想而知，在高并发环境下，它将会造成阻塞，且会有大量的上下文切换。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[Kubernetes学习路径 & 教程]]></title>
        <id>https://blog.xwl.io/post/WpUHlquQY/</id>
        <link href="https://blog.xwl.io/post/WpUHlquQY/">
        </link>
        <updated>2021-04-23T16:31:44.000Z</updated>
        <content type="html"><![CDATA[<p>本文学习路径抄录了该项目大量文字 <a href="https://github.com/caicloud/kube-ladder">kube-ladder</a>，相关知识会慢慢补齐。</p>
<h2 id="入门篇">入门篇</h2>
<ul>
<li>Kubernetes 的背景和优势</li>
<li>Kubernetes 环境的安装部署</li>
<li>Kubernetes 常用资源的使用方法</li>
</ul>
<p>包括不限于Node、Pod、Service、Deployment、Namespace、ConfigMap、Secret。</p>
<h2 id="原理篇">原理篇</h2>
<p>目标是了解Kubernetes的架构的核心组成部分，及其工作原理，容器从启动到结束整个生命周期的过程。</p>
<ul>
<li><a href="/post/hhkktAeFo/">Kubernetes 的基础架构</a></li>
<li>Kubernetes 容器调度的基本流程</li>
</ul>
<p>运维人员基本做到这一步就可以了，下面的内容将会涉及到开发。</p>
<h2 id="集成篇">集成篇</h2>
<p>本节的目标是使用apiserver相关的接口，用于外部的服务集成。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[kubernetes基础架构]]></title>
        <id>https://blog.xwl.io/post/hhkktAeFo/</id>
        <link href="https://blog.xwl.io/post/hhkktAeFo/">
        </link>
        <updated>2021-04-22T13:46:29.000Z</updated>
        <content type="html"><![CDATA[<h2 id="基础组件">基础组件</h2>
<p><img src="https://blog.xwl.io/post-images/1619099263782.jpg" alt="" loading="lazy"><br>
上图是kubernetes的基本组成部分，以下将简单描述一下其组件及其功能。</p>
<h3 id="master">Master</h3>
<ul>
<li>API Server：管理集群资源的唯一入口</li>
<li>Controller-Manager：一个资源对应一个控制器
<ul>
<li>Node Controller</li>
<li>Deployment Controller</li>
<li>Namespace Controller</li>
<li>...</li>
</ul>
</li>
<li>Scheduler：节点调度，选择Worker节点部署
<ul>
<li>Filter：选择符合Pod Spce描述的Node</li>
<li>Score：打分和排序</li>
<li>Reserve：缓存数据，表示这个Pod已经分配到这个Node上</li>
</ul>
</li>
<li>etcd：用于存储集群相关的数据</li>
</ul>
<h3 id="worker">Worker</h3>
<ul>
<li>kube-proxy：提供网络代理、负载均衡
<ul>
<li>实现的Proxy Mode支持iptables、ipvs <a href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies?_blank">Virtual IPs and service proxies</a></li>
<li>扩展阅读：<a href="https://www.cnblogs.com/tencent-cloud-native/p/13566340.html">性能提升40%: 腾讯 TKE 用 eBPF 绕过 conntrack 优化 K8s Service</a></li>
</ul>
</li>
<li>kubelet：管理本机的容器
<ul>
<li>基于 PodSpec 来工作的，每个 PodSpec 是一个描述 Pod 的 YAML 或 JSON 对象。</li>
</ul>
</li>
</ul>
<h2 id="身份验证">身份验证</h2>
<p>每一次的访问请求都需要进行合法性的检验，其中包括身份验证、操作权限验证以及操作规范验证等，需要通过一系列验证通过之后才能访问。</p>
<h3 id="工作流程">工作流程</h3>
<ol>
<li>认证：验证账号的有效性</li>
<li>鉴权：拥有哪些访问权限</li>
<li>准入控制：自定义插件，API请求拦截器，它可以更改请求对象，甚至完全拒绝请求。</li>
</ol>
<h3 id="认证">认证</h3>
<p>拥有三种认证方式，分别是：</p>
<ul>
<li>Http Basic Authentication</li>
<li>基于证书认证（CA）</li>
<li>基于token认证</li>
</ul>
<h3 id="鉴权">鉴权</h3>
<p>基于RBAC，也就是角色访问控制。通俗的说，就是将权限赋予给角色，然后将角色绑定要用户主体上。</p>
<ul>
<li>主体
<ul>
<li>user</li>
<li>group</li>
</ul>
</li>
<li>角色
<ul>
<li>role：特定命名空间访问权限</li>
<li>ClusterRole：所有命名空间访问角色</li>
</ul>
</li>
<li>角色绑定
<ul>
<li>RoleBinding：角色绑定到主体</li>
<li>ClusterRoleBinding：集群角色绑定到主体</li>
</ul>
</li>
</ul>
<h3 id="准入控制">准入控制</h3>
<blockquote>
<p>我从网上扒了一个例子，供参考</p>
</blockquote>
<p>去年曝光的 runC 漏洞（CVE-2019-5736），它被利用的原因之一就是容器内进程都是以 root 权限运行的。下面我们以这个问题为例，一起利用准入控制器 webhook 建立自定义安全策略。</p>
<p>为了解决上述问题，工程师可以使用自定义的变更准入控制器 Webhook 使默认设置变得更安全：除非明确要求，否则 webhook 将强制要求 Pod 以非 root 身份运行（示例中为分配 ID 1234）。</p>
<p>请注意，这个设置不会影响到集群中的工作负载，包括那些明确需要 root 权限的工作负载。</p>
<p>完整代码请见以下 <a href="https://github.com/stackrox/admission-controller-webhook-demo">admission-controller-webhook-demo</a></p>
<h2 id="pod-启动流程">Pod 启动流程</h2>
<p>最后给大家分享一下容器的完整创建流程，对此有一个大概的认知。</p>
<figure data-type="image" tabindex="1"><img src="https://blog.xwl.io/post-images/1619101364760.jpg" alt="" loading="lazy"></figure>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[haproxy源码阅读（二）处理任务流程]]></title>
        <id>https://blog.xwl.io/post/TZUaQzhYM/</id>
        <link href="https://blog.xwl.io/post/TZUaQzhYM/">
        </link>
        <updated>2021-04-16T15:45:38.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>所有源码分析基于haproxy version 1.6.14</p>
</blockquote>
<p>直接进入正题</p>
<p>核心代码如下<code>task.c</code></p>
<pre><code class="language-c">void process_runnable_tasks()
{
	struct task *t;
	unsigned int max_processed;

	tasks_run_queue_cur = tasks_run_queue; 	nb_tasks_cur = nb_tasks;
	max_processed = tasks_run_queue;

	if (!tasks_run_queue)
		return;

	if (max_processed &gt; 200)
		max_processed = 200;

	if (likely(niced_tasks))
		max_processed = (max_processed + 3) / 4;

	while (max_processed--) {
		if (unlikely(!rq_next)) {
			rq_next = eb32_lookup_ge(&amp;rqueue, rqueue_ticks - TIMER_LOOK_BACK);
			if (!rq_next) {
				rq_next = eb32_first(&amp;rqueue);
				if (!rq_next)
					break;
			}
		}

		t = eb32_entry(rq_next, struct task, rq);
		rq_next = eb32_next(rq_next);
		__task_unlink_rq(t);

		t-&gt;state |= TASK_RUNNING;
		t-&gt;calls++;
		if (likely(t-&gt;process == process_stream))
			t = process_stream(t);
		else
			t = t-&gt;process(t);

		if (likely(t != NULL)) {
			t-&gt;state &amp;= ~TASK_RUNNING;
			if (t-&gt;expire)
				task_queue(t);
		}
	}
}
</code></pre>
<h2 id="简要说明">简要说明</h2>
<p>首先<code>max_processed</code>限制了每次最大只能处理200个任务</p>
<pre><code class="language-c">if (unlikely(!rq_next)) {
    rq_next = eb32_lookup_ge(&amp;rqueue, rqueue_ticks - TIMER_LOOK_BACK);
    if (!rq_next) {
        /* we might have reached the end of the tree, typically because
         * &lt;rqueue_ticks&gt; is in the first half and we're first scanning
         * the last half. Let's loop back to the beginning of the tree now.
         */
        rq_next = eb32_first(&amp;rqueue);
        if (!rq_next)
            break;
    }
}
</code></pre>
<p>如果下一个处理的任务为空，那么将回到队列的最前方。</p>
<pre><code class="language-c">t = eb32_entry(rq_next, struct task, rq);
rq_next = eb32_next(rq_next);
__task_unlink_rq(t);
</code></pre>
<p>我们获取到下一个任务之后，清除任务的队列信息，也就是删除当前的树节点</p>
<pre><code class="language-c">if (likely(t-&gt;process == process_stream))
	t = process_stream(t);
else
	t = t-&gt;process(t);

if (likely(t != NULL)) {
	t-&gt;state &amp;= ~TASK_RUNNING;
	if (t-&gt;expire)
		task_queue(t);
}
</code></pre>
<p>判断如果是处理请求的话，使用<code>process_stream</code>，还有其他多种情况，比如：</p>
<ul>
<li>process_check</li>
<li>server_warmup</li>
<li>process_email_alert</li>
<li>dns_process_resolve</li>
<li>session_expire_embryonic</li>
</ul>
<h2 id="函数分析">函数分析</h2>
<h3 id="process_stream">process_stream</h3>
<p>这个函数只怕是有几千行哦，又长又臭：）<br>
这个是haproxy处理任务的核心函数，代码内有一段注释说明。</p>
<blockquote>
<p>Processes the client, server, request and response jobs of a stream task, then puts it back to the wait queue in a clean state</p>
</blockquote>
<p>然后进行一些初始化工作</p>
<pre><code class="language-c">struct channel *req, *res;
struct stream_interface *si_f, *si_b;

req = &amp;s-&gt;req;
res = &amp;s-&gt;res;

si_f = &amp;s-&gt;si[0];
si_b = &amp;s-&gt;si[1];
</code></pre>
<p><code>si_f</code>生产者，对应的是frontend端的句柄；而<code>si_b</code>为消费者，对应的backend端的句柄。</p>
<pre><code class="language-c">if (unlikely(s-&gt;pending_events &amp; TASK_WOKEN_TIMER)) {
    ...
    
    goto update_exp_and_leave
}
</code></pre>
<p>此条件判断是否有超时事件，<code>TASK_WOKEN_TIMER</code>在任务超时的时候会被唤醒，然后开始检查<code>si_f</code>、<code>si_b</code>、<code>req channel</code>和<code>res channel</code>，随之将连接关闭。</p>
<p>然后进入<code>update_exp_and_leave</code>函数，此函数会将初始化过期时间，是其内部实现的一个ticks。释放buffer之后，使用<code>stream_res_wakeup</code>函数将其重新加入队列。</p>
<pre><code class="language-c">if (si_b-&gt;state == SI_ST_CON) {
	if (unlikely(!sess_update_st_con_tcp(s)))
		sess_update_st_cer(s);
	else if (si_b-&gt;state == SI_ST_EST)
		sess_establish(s);
}
</code></pre>
<p>如果是状态为SI_ST_CON（发起连接请求），则进入此流程。检查连接是否是正常，<code>sess_update_st_con_tcp</code>检查连接，如果之前的连接建立失败了，使用<code>sess_update_st_cer</code>处理善后事宜，清空session等操作，如果需要重试的话，则使用<code>process_srv_queue</code>重新进入proxy queue。</p>
<p>如果状态是SI_ST_EST，说明连接建立成功，使用<code>sess_establish</code>初始化一些参数。</p>
<h3 id="resync_stream_interface">resync_stream_interface</h3>
<p>作为子分支存在，主要用于检测连接可用性。</p>
<pre><code class="language-c">if (unlikely(si_f-&gt;state == SI_ST_DIS))
	si_f-&gt;state = SI_ST_CLO;

if (unlikely(si_b-&gt;state == SI_ST_DIS)) {
	si_b-&gt;state = SI_ST_CLO;
	srv = objt_server(s-&gt;target);
	if (srv) {
		if (s-&gt;flags &amp; SF_CURR_SESS) {
			s-&gt;flags &amp;= ~SF_CURR_SESS;
			srv-&gt;cur_sess--;
		}
		sess_change_server(s, NULL);
		if (may_dequeue_tasks(srv, s-&gt;be))
			process_srv_queue(srv);
	}
}
</code></pre>
<p><code>may_dequeue_tasks</code> 用于判断是否有必要开始下个连接</p>
<ul>
<li><code>s-&gt;nbpend</code> 等待处理的连接数</li>
<li><code>srv_is_usable</code> 是否有可用的服务器</li>
<li><code>maxconn</code> 最大连接数等</li>
</ul>
<p><code>process_srv_queue</code> 检测proxy queue的是否有正在等待处理的连接，并将它们全部唤醒。</p>
<h3 id="resync_request">resync_request</h3>
<p>用于分析请求，主要函数</p>
<ul>
<li>tcp_inspect_request</li>
<li>http_wait_for_request</li>
<li>http_wait_for_request_body</li>
<li>http_process_req_common</li>
<li>process_switching_rules</li>
<li>tcp_inspect_request</li>
<li>http_process_req_common</li>
<li>process_server_rules</li>
<li>http_process_request</li>
<li>process_sticking_rules</li>
<li>http_request_forward_body</li>
</ul>
<h3 id="resync_response">resync_response</h3>
<ul>
<li>tcp_inspect_response</li>
<li>http_wait_for_response</li>
<li>process_store_rules</li>
<li>http_process_res_common</li>
<li>http_response_forward_body</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[haproxy源码阅读（一）主循环流程]]></title>
        <id>https://blog.xwl.io/post/s5EVafZW4/</id>
        <link href="https://blog.xwl.io/post/s5EVafZW4/">
        </link>
        <updated>2021-04-15T15:39:58.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>所有源码分析基于haproxy version 1.6.14</p>
</blockquote>
<p>首先分析核心代码<code>haproxy.c</code></p>
<pre><code class="language-c">/* Runs the polling loop */
void run_poll_loop()
{
	int next;

	tv_update_date(0,1);
	while (1) {
		/* Process a few tasks */
		process_runnable_tasks();

		/* check if we caught some signals and process them */
		signal_process_queue();

		/* Check if we can expire some tasks */
		next = wake_expired_tasks();

		/* stop when there's nothing left to do */
		if (jobs == 0)
			break;

		/* expire immediately if events are pending */
		if (fd_cache_num || tasks_run_queue || signal_queue_len || applets_active_queue)
			next = now_ms;

		/* The poller will ensure it returns around &lt;next&gt; */
		cur_poller.poll(&amp;cur_poller, next);
		fd_process_cached_events();
		applet_run_active();
	}
}
</code></pre>
<h2 id="简要说明">简要说明</h2>
<ol>
<li>process_runnable_tasks 处理可运行的任务</li>
<li>signal_process_queue   处理信号队列，如果捕获了信号则需要处理</li>
<li>wake_expired_tasks     处理超时任务</li>
<li>cur_poller.poll 更新fd事件到缓存</li>
<li>fd_process_cached_events 处理fd事件</li>
</ol>
<h2 id="函数分析">函数分析</h2>
<p>整体描述下函数的作用</p>
<h3 id="process_runnable_tasks">process_runnable_tasks</h3>
<p>取出队列中的任务，调用<code>process_stream</code>函数处理，返回之后重新将task放入等待队列<br>
主要任务</p>
<ul>
<li>根据预设的规则设置一个backend<br>
<code>process_switching_rules</code> -&gt; <code>stream_set_backend</code></li>
<li>根据相应的调度算法，选择后端服务器，并添加到队列中<br>
<code>sess_prepare_conn_req</code> -&gt; <code>srv_redispatch_connect</code> -&gt; <code>assign_server_and_queue</code> -&gt; <code>assign_server</code> -&gt; <code>chash_get_next_server</code></li>
<li>后端服务器请求已满，添加到proxy队列<br>
<code>pendconn_add</code></li>
</ul>
<h3 id="signal_process_queue">signal_process_queue</h3>
<p>自身实现的信号处理机制，接收到信号之后输出到队列，然后在处理信号队列，保证所有请求处理完之后再关闭</p>
<h3 id="wake_expired_tasks">wake_expired_tasks</h3>
<p>唤醒超时任务，队列分为run queue／wait queue，该函数就是检查wait queue任务，并将其输出到run queue中，以便后续处理。</p>
<h3 id="cur_pollerpoll">cur_poller.poll</h3>
<p>获取所有活动的fd，并将其更新到cache中</p>
<p>主要函数</p>
<ul>
<li>_do_poll
<ul>
<li>epoll_wait</li>
<li>fd_may_recv</li>
<li>fd_may_send
<ul>
<li>fd_update_cache</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="fd_process_cached_events">fd_process_cached_events</h3>
<p>处理fd事件，建立连接、数据收发等</p>
<p>主要函数</p>
<ul>
<li>conn_fd_handler
<ul>
<li>si_conn_recv_cb
<ul>
<li>raw_sock_to_pipe/ssl_sock_to_buf</li>
<li>raw_sock_to_buf</li>
</ul>
</li>
<li>si_conn_send_cb</li>
</ul>
</li>
</ul>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[使用vscode调试haproxy]]></title>
        <id>https://blog.xwl.io/post/tS0UUUJy6/</id>
        <link href="https://blog.xwl.io/post/tS0UUUJy6/">
        </link>
        <updated>2021-04-15T15:29:08.000Z</updated>
        <content type="html"><![CDATA[<h2 id="基础环境配置">基础环境配置</h2>
<p>mac环境下，自带的是clang，在编辑haproxy的时候会出现一系列的warning，所以先安装下gcc，haproxy官方测试通过的只有4.x版本</p>
<pre><code>brew install gcc@4.9
</code></pre>
<p>然后修改haproxy的Makefile，120行。</p>
<pre><code>CC = /usr/local/Cellar/gcc\@4.9/4.9.4_1/bin/gcc-4.9
</code></pre>
<p>编译安装</p>
<pre><code>make TARGET=osx
make install PREFIX=/opt/haproxy
</code></pre>
<h2 id="vscode-配置">vscode 配置</h2>
<ul>
<li>tasks.json</li>
</ul>
<pre><code>{
    &quot;version&quot;: &quot;2.0.0&quot;,
    &quot;tasks&quot;: [
        {
            &quot;label&quot;: &quot;haproxy&quot;,
            &quot;type&quot;: &quot;shell&quot;,
            &quot;command&quot;: &quot;sudo make TARGET=osx &amp;&amp; sudo make install PREFIX=/opt/haproxy &amp;&amp; sudo make clean&quot;,
            &quot;problemMatcher&quot;: [
                &quot;$gcc&quot;
            ]
        }
    ]
}
</code></pre>
<p>此时运行任务的时候就自动执行tasks.json的任务，进行编译，完成之后就能顺利调试。</p>
<ul>
<li>launch.json</li>
</ul>
<pre><code>{
    &quot;version&quot;: &quot;0.2.0&quot;,
    &quot;configurations&quot;: [
        {
            &quot;name&quot;: &quot;(gdb) Launch&quot;,
            &quot;type&quot;: &quot;cppdbg&quot;,
            &quot;request&quot;: &quot;launch&quot;,
            &quot;program&quot;: &quot;/opt/haproxy/sbin/haproxy&quot;,
            &quot;args&quot;: [&quot;-f&quot;, &quot;/opt/haproxy/etc/haproxy.cfg&quot;],
            &quot;stopAtEntry&quot;: false,
            &quot;cwd&quot;: &quot;${workspaceFolder}&quot;,
            &quot;environment&quot;: [],
            &quot;externalConsole&quot;: false,
            &quot;MIMode&quot;: &quot;lldb&quot;
        }
    ]
}
</code></pre>
<p>这个配置是用于调试环境下的，执行二进制程序环境的命令，以及使用的调试工具gdb/lldb。</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[别让我们的野心配不上才华｜圈圈@TEDx]]></title>
        <id>https://blog.xwl.io/post/sMLLztYXw/</id>
        <link href="https://blog.xwl.io/post/sMLLztYXw/">
        </link>
        <updated>2021-04-13T13:51:05.000Z</updated>
        <content type="html"><![CDATA[<blockquote>
<p>孙圈圈，移动学习品牌“圈外同学” 创始人兼CEO，领英洞察、36Kr专栏作家，毕业于南京大学经济学系，曾担任美世咨询（全球最大的人力资源管理咨询公司）总监，为多家国内外知名企业服务，设计组织架构和人才发展体系，著有职场类畅销书《请停止无效努力:如何用正确的方法快速进阶》。</p>
</blockquote>
<h2 id="一-看人很准的我栽在实习生手上">一、 看人很准的我，栽在实习生手上</h2>
<p>我曾经是一名管理咨询顾问，从事咨询工作8年多，当时我主要的工作职责是帮公司制定他们的人才发展战略，同时研究什么样特质的人适合做什么样的岗位。</p>
<p>所以我的工作中有一部分是看人。</p>
<p>一些大公司在选拔高管继任者的时候，会找到我们，我会花几个小时跟候选人相处，评估他们各方面的能力，看是否符合岗位要求。</p>
<p>这些企业高管的候选人，往往是中年男性，他们成熟、世故、善于伪装，“宁愿相信世界上有鬼，也别相信中年男人那张嘴”。</p>
<p>所以在这种训练下，我一直认为，自己看人很准，直到有一次，“栽”到了实习生手上。</p>
<p>那时候，我有两个实习生，其中一个男生，聪明、理性、在复旦念书，而另一个女生，学校一般、面试表现一般。各位，如果你们是我，你会看好哪一个呢？我跟大多数人一样，看好前面一个，也着力培养。</p>
<p>几个月之后，我让他们同时帮我写一份项目建议书，男生做得不错，分析详细、逻辑严密。</p>
<p>但是给我惊喜的却是这个女生，报告非常有洞见，她甚至利用社交网络去找了行业内部人士做了访谈。为什么几个月会发生反转呢？</p>
<p>我百思不得其解，跟一个前辈聊起这个问题，她问我两个实习生的工作态度、我在他们身上花的时间、他们做的事情有无差异等等，最后她问到：两个小朋友的职业目标是什么？</p>
<p>那一刻我突然恍然大悟，我想起自己曾经跟他们聊过“野心”这个话题。</p>
<p>男生说，他的野心是成为跨国公司CEO、做一个出色的职业经理人，所以他再晚也会做完我分配的工作。</p>
<p>但是都会按照我给的步骤去做，不会过于激进地创新，因为他不敢犯错。</p>
<p>而女生呢，会问我“如果我5年后要创立自己的公司，现在做咨询合适吗？”可我甚至还没有决定是否要留下她呢！</p>
<p>她常常跟我要求一些能力以外的事情去做，还会尝试一些她认为可行的方法，有时候做成，也有时候搞砸，虽然给人不稳定的感觉，但这么一来，她的确成长却更快了。</p>
<p>从那以后，我在选人用人的时候，我会额外关注一个人的野心，也就是他做事的动力。</p>
<h2 id="二-动力不是驱动我们享受的而是驱动我们付出的">二、 动力不是驱动我们享受的，而是驱动我们付出的</h2>
<p>我有必要解释一下，这里的动力是什么含义。可能很多人说：动力，就是自己喜欢或者想要的东西。</p>
<p>那么在座各位，你喜欢什么呢？</p>
<p>我曾经问过很多人这个问题，得到的回答基本是：睡觉睡到自然醒，数钱数到手抽筋，工作地点离家近……</p>
<p>Ok，这些不是动力，也不是野心，那是什么呢？</p>
<p>这些是人性本能。</p>
<p>那什么是动力呢？人类历史上1953年第一次登上珠峰，但在1924年，就有人几乎登上过，这个人叫乔治马洛里。</p>
<p>剑桥大学毕业，凯恩斯的同学加好友，有一个非常恩爱的妻子，最重要的是，颜值超高！简直是人生赢家！我们都想成为他这样的人，不是吗？</p>
<p>但是他却多次冒着生命危险登珠峰，那可是在100年前，人类没有去过珠峰，所以没有地图，那时候没有羽绒服，更不用提高原反应。</p>
<p>实际上，马洛里在第二次尝试的时候，就因为雪崩，眼睁睁看着7个队友丧生，但他还是去了第三次。</p>
<p>然后在离山顶只有几百米的地方，他永远留在了那里，直到几十年后，人们发现了他的尸体。</p>
<p>记者曾经问他为什么，他说“Because it’s there”，就是那句著名的“因为，山就在那里”。</p>
<p>所谓本能，就是明知道一些事是对的，但是自己做不到；而所谓动力，就是我们能够反本能地去做到那些事情。</p>
<p>怕冷、怕死、怕累，是出于本能；而克服这些“怕”去爬珠峰，是出于动力。所以，动力不是让我们享受的，恰恰相反，是让我们甘愿付出的。</p>
<h2 id="三-成功者的共性是动力">三、 成功者的共性是动力</h2>
<p>这种动力，到底有多重要呢？</p>
<p>我曾经跟之前的同事一起，给过去服务过的企业高管和个人客户做了个数据分析，分析对象都是各大企业的成功领导者。</p>
<p>在这些人当中，各个跟领导力相关的能力项，几乎都可以找到反面的例子，比如有人战略思维欠缺，有人团队管理方面不够成熟，但也能成为成功领导者。</p>
<p>可是，几乎没有人缺乏passion for success（也就是追求成功的热情）这一项。</p>
<p>为什么动力会如此重要呢？它在我们的发展过程中，起到什么样的作用呢？</p>
<p>相信大家都听说过冰山模型，是美国著名心理学家麦克利兰提出来的，它全面地描述了一个人的个体素质要素。</p>
<p>一条海平面把冰山分成了上下两部分。</p>
<p>海平面上面的部分，是知识、技能和能力，解决了一个人“能不能”做某件事情；而天赋特性包括价值观、性格特质等等，解决了一个人“愿不愿”做某件事情。</p>
<p>这三类要素是自下而上逐渐影响的，底层要素决定了上层，比如我们有动力学习，然后才有学习能力的提升，然后有了学习能力，也能学会更多知识。</p>
<p>根据研究，冰山底层的要素中，光个性特质就能够解释员工绩效差异的35%，而冰山底层的因素加起来差不多决定了一个人的70%。</p>
<p>并且越往底层的要素越难被我们发现，同时也越难被改变，比如个性特质，基本在成年之后就达到稳定状态，除非遭遇重大的人生变故。</p>
<p>所以，如果我们所做的事情，跟自己冰山下面的要素相违背，相当于我们用10分的努力，最多得到3分的结果；而另一个人，只要选对了事情，他可能就有7分了。</p>
<p>找到我们的动力，就是如此重要。</p>
<h2 id="四-大部分人的问题是野心配不上才华">四、 大部分人的问题，是野心配不上才华</h2>
<p>我们经常听说这样一句话，“要让才华配得上自己的野心”。 可现实情况其实恰恰相反，大部分人的野心，其实是配不上才华的。</p>
<p>因为，才华是能力，而野心是动力，我们花了很多时间提升自己，可却不知道为什么。</p>
<p>野心配不上才华会如何呢？我不知道各位有没有过这种时刻，反正大部分我都有过：</p>
<p>高考之前以分数为目标，被家长推着走，大学的时候跟同学混着走，4年毕业之后，突然面临一个问题“我要做什么工作”，于是彻底懵逼；</p>
<p>之后，找到一份不喜欢也不讨厌的工作，拿着一份不高也不低的工资，想要做点什么来改变，可不知道怎么改变；</p>
<p>然后，因为不知道要做什么，所以就到处找事做，办了健身卡、买了知识付费产品、打算考几个证，也的确学到了一些东西，但是都没坚持下去。</p>
<p>最后放弃了折腾，安慰自己说“可能人生就是这样吧”，对很多事情都没有了热情，除了刷抖音的时候。</p>
<p>这些问题背后，可能就是野心配不上才华。当然，我们大多数人如何概括这种现象呢？统称两个字：迷茫。</p>
<p>所以，如果我们去问一个年轻人：你迷茫吗？他多半会回答说：哎？你怎么知道？</p>
<p>我当然知道，我们都迷茫嘛！</p>
<p>所以，找到我们的野心，让它对得起我们的才华和努力！</p>
<h2 id="五-这个方法帮我找到了野心改变了我的人生轨迹">五、 这个方法，帮我找到了野心，改变了我的人生轨迹</h2>
<p>如何才能找到呢？</p>
<p>在我快30岁的时候，我成为了公司晋升最快的咨询顾问，而且如果继续待下去，可能会成为这里最年轻的合伙人。</p>
<p>但是，突然某一天，我不想继续了。</p>
<p>咨询公司或者说所有的大公司，都有一个非常清晰的职业发展通道，好像一把梯子，只要我上了梯子、往上爬一格，就会有人给我加油、有人跟我竞争、有人给我鲜花和掌声。</p>
<p>然后在那种氛围下，我竭尽全力一直往上爬，这些给了我很强的外部动力，让我待了8年。</p>
<p>可是，当我快爬到顶的时候，我看到了梯子最顶端的风景，我突然发现那不是我想要的。我不要在这儿玩儿了，可我要什么，我不知道。</p>
<p>于是，我开始自我治疗，当时跟很多人聊过，也找了很多资料，结合了很多方法，最终真的找到了一个方法，让我找到了自己的野心，也改变了我的人生轨迹。</p>
<p>后来我分享过给很多人，也改变了他们。今天，我分享给你们。</p>
<p>第一步，我停了下来，开始回忆自己过去8年，回忆自己特别兴奋或者厌恶的时刻。也就是，回忆过去这些年的巅峰体验。</p>
<p>为什么要回忆体验呢？很简单，我们的野心本身就来源于感觉。</p>
<p>比如，有人会说自己想赚一个亿，但钱并不是我们真正追求的东西，我们想要钱，是看中了背后的安全感，还是给了家人团聚的可能，还是证明自己成功呢？</p>
<p>这背后的感觉，才是我们要找的。</p>
<p>第二步，我找了10个朋友，都是跟我非常亲近的朋友，问他们，我在做什么事情的时候最专注、最热情、两眼放光。</p>
<p>为什么要找朋友呢？因为我们看自己的很多行为往往觉得理所当然、习以为常，但是我们的朋友，他们会从旁观者的角度来告诉我们真相。</p>
<p>那些你觉得理所当然可别人觉得匪夷所思的事情，可能就是你的热情所在。</p>
<p>之后，我找了一个周末的下午，把自己关在房间里面，面前铺开一大叠纸，开始一个个写自己想要做到的事情，就这样写了100多个。</p>
<p>人生几十年，我第一次知道自己这么贪心，想要得这么多。在写的过程中，大概有五六个，都曾经让我心潮澎湃。</p>
<p>然后，看着这五六条，我再一个个删。</p>
<p>我告诉自己：删掉，就意味着我这辈子不可能实现它了。这个过程中，我从刚才的极度兴奋变成极度崩溃。</p>
<p>最后，一张纸上留下了最后一条。</p>
<p>那一条是：影响并帮助他人成长。</p>
<p>想象我不去服务企业，而是我能够把自己的专业知识和经验输出，直接帮助一个人，我就觉得无比兴奋！</p>
<p>所以，做完最后这一步，找到野心之后，再去找到能够满足我们野心的事情就可以了。</p>
<p>于是，在那天下午之后的几个月，我就从咨询公司辞职了，开始创业，做一家帮助年轻人成长的公司（注：圈外同学）。</p>
<p>我很庆幸当时自己找到了我要的答案。</p>
<h2 id="六-我找到了野心但我又输掉了它">六、 我找到了野心，但我又输掉了它</h2>
<p>但是，故事还没结束，后来我跟团队一起，做了一件更加刺激的事情。</p>
<p>我们差不多10几个人，把我们的野心放在一起，除了我上面说的那条之外，还有一些很吸引人的。</p>
<p>比如找到相伴一生的灵魂伴侣，比如能够流芳百世，比如永远美丽动人，等等。</p>
<p>然后我们做了一个野心拍卖会，每个人分到10个筹码，拍自己要的那个东西，这些筹码代表的是自己拥有的时间。</p>
<p>轮到我的拍品的时候，我先叫了1个筹码，然后有人叫到2，很明显，另一个人也想要这个，然后我叫3的时候，她没有叫4，而是直接10个筹码all in了。</p>
<p>我一下子蒙了，那是我最想要的东西，可它现在属于别人，我觉得自己快要哭出来了。</p>
<p>回顾刚才的拍卖过程，我明明知道那是我唯一想要的东西，我应该做的是10个筹码all in。</p>
<p>但是我觉得，有10个筹码嘛，说不定可以用几个拍到自己最想要的，然后剩一些来拍其他物品，毕竟那些也都很有吸引力啊！</p>
<p>可当有人all in的时候，我输掉了。</p>
<p>这像极了我们的现实人生，很多时候，我们明明有自己内心想要的东西，但是当我们看到同学、朋友、亲戚手里的其他东西，又觉得“哎，好像也不错”。</p>
<p>非常羡慕他们，会想是不是也可以去试试，但最后，我们疲于奔命、什么也没有得到。</p>
<p>后来在我创业过程中，面临过很多次困境，也面临过很多诱惑，但每当这个时候，我就会想起拍卖会上，我失去野心的那种痛苦，然后我总能更容易地做出选择。</p>
<p>回到刚开始那两个实习生的故事，他们现在发展得都不错，男生在一家500强公司，而女生呢，现在在我们创业团队，而且她就是那个在拍卖会上跟我抢野心的人。</p>
<p>他们的野心和才华，都得到了最好的安排。</p>
<p>所以各位，我今天特别想分享这个观点：花一点时间，去找到自己的野心，然后聚焦，让它配得上我们的才华！</p>
<p>我们都以为，那种所谓“野心”都离我们太远了，只有那些改变世界的人，比如乔布斯，才配得上谈野心。</p>
<p>但是，我们所有人都有属于自己的野心。</p>
<p>它并不是一个所有人都一致的东西，无论我们的野心是“改变世界”还是“家庭美满”，都是有价值的。</p>
<p>因为，它会让我们专注于自己的需求，让我们不再抱怨这样那样的不顺心，不再纠结这样那样的选择，不再羡慕别人有这样那样的东西。</p>
<p>我们的人生就像那座冰山，海平面上会有无数狂风暴雨，但只要找到了自己的野心，我们就能在海平面底下安然无恙。</p>
<p>所以，找到我们的野心，让它配得上我们的才华！</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[关于本站服务构建]]></title>
        <id>https://blog.xwl.io/post/5wRgq8uqf/</id>
        <link href="https://blog.xwl.io/post/5wRgq8uqf/">
        </link>
        <updated>2021-03-31T17:20:49.000Z</updated>
        <content type="html"><![CDATA[<h2 id="简介">简介</h2>
<p>本站基于<a href="https://github.com/getgridea/gridea">Gridea</a>构建</p>
<p>也曾折腾过Wordpress、Ghost、Hexo、Hugo等博客，在来回迁移的痛苦中，却没有多少文章产出。</p>
<p>但请不要忘记初心❤️</p>
<h2 id="gridea的同步问题">Gridea的同步问题</h2>
<p>经常因为网络问题，出现同步失败的情况，是因为Github被墙的缘故，使用<a href="http://ping.chinaz.com">Ping工具</a>去检查一下，然后找个延迟低的IP地址，替换一下Host即可。</p>
<h2 id="主流开源博客对比">主流开源博客对比</h2>
<p>Wordpress：什么都有，唯一的毛病都是慢。<br>
Ghost：生态不错，但考虑到国内的网络环境和本地化程度，只适合做英文站。<br>
Hexo：折腾型选手，缺点是文章过多编译时太慢。<br>
Hugo：折腾型选手，编译效率上去了，但是写文章体验不是很好。<br>
Gridea：有独立客户端，几乎没有生态，但用起来很方便，适合专注创作的朋友。</p>
<h2 id="总结">总结</h2>
<p>中文博客推荐Gridea，而英文站推荐<a href="https://github.com/tryghost/ghost">Ghost</a>。</p>
]]></content>
    </entry>
</feed>