{"themeConfig":{"themeName":"Gridea-theme-Chic","postPageSize":10,"archivesPageSize":50,"siteName":"许大仙的博客","siteDescription":"一个运维人的成长历程","footerInfo":"","showFeatureImage":false,"domain":"https://xwl.io","postUrlFormat":"SHORT_ID","tagUrlFormat":"SHORT_ID","dateFormat":"YYYY-MM-DD","feedFullText":false,"feedCount":20,"archivesPath":"archives","postPath":"post","tagPath":"tag"},"posts":[{"content":"简介 OpenResty对于进程间的通讯，提供了共享内存的机制，也就是名为ngx.shared的方法。 我们会基于它去进行封装，更多的应用场景也是用于缓存。 缓存有两个原则 一是越靠近用户的请求越好，比如能用本地缓存的就不要发送HTTP请求，能用CDN缓存的就不要打到web服务器，能用nginx缓存的就不要用数据库的缓存。 二是尽量使用本进程和本机的缓存解决，因为跨了进程和机器甚至机房，缓存的网络开销就会非常大，在高并发的时候会非常明显。 根据以上原则，会优先使用进程内的缓存，OpenResty提供了一个进程缓存模块lua-resty-lrucache，会把共享内存作为二级缓存。 缓存模块 通常情况，我们会用成熟的组件lua-resty-mlcache做多级缓存，它提供了三级缓存机制。 它的架构如下： 我们直接贴一下官方的示例 # nginx.conf http { lua_package_path &quot;/path/to/lua-resty-mlcache/lib/?.lua;;&quot;; lua_shared_dict cache_dict 1m; init_by_lua_block { local mlcache = require &quot;resty.mlcache&quot; local cache, err = mlcache.new(&quot;my_cache&quot;, &quot;cache_dict&quot;, { lru_size = 500, -- size of the L1 (Lua VM) cache ttl = 3600, -- 1h ttl for hits neg_ttl = 30, -- 30s ttl for misses }) if err then end _G.cache = cache } server { listen 8080; location / { content_by_lua_block { local function callback(username) return db:get_user(username) -- { name = &quot;John Doe&quot;, email = &quot;john@example.com&quot; } end local user, err = cache:get(&quot;my_key&quot;, nil, callback, &quot;John Doe&quot;) ngx.say(user.username) -- &quot;John Doe&quot; } } } } 以上的示例很好了描述了整个程序运行的逻辑，在init阶段初始化缓存，然后用_G变量赋予全局变量，在使用阶段cache:get获取指定Key的缓存，缓存未命中就会调用L3，也就是callback方法。 缓存失效风暴 但这个示例中缺失了lua-resty-lock这个组件的调用。 通常在L3阶段都是查询外部的数据库，如果在缓存失效的一瞬间，一万个并发请求同时到达，那么将会产生一万次数据查询，事实上我们只需要查询一次即可。 为了防止在L3阶段发生这种情况（缓存失效风暴），所以利用好锁的机制非常重要。 我们将局部配置修改如下： lua_shared_dict cache_dict 1m; lua_shared_dict cache_lock 1m; init_by_lua_block { local mlcache = require &quot;resty.mlcache&quot; local cache, err = mlcache.new(&quot;my_cache&quot;, &quot;cache_dict&quot;, { lru_size = 500, -- size of the L1 (Lua VM) cache ttl = 3600, -- 1h ttl for hits neg_ttl = 30, -- 30s ttl for misses shm_locks = &quot;cache_lock&quot;, resty_lock_opts = { exptime = 10, timeout = 5 } }) if err then end } 进程之间数据同步 这个问题我们使用lua-resty-worker-events模块解决。 此模块提供了一种向Nginx服务器中的其他工作进程发送事件的方法。通信是通过一个共享的存储区进行的，事件数据将存储在该存储区中。 结合我们之前的缓存使用场景，在一个Worker中的缓存更新之后，要通知其他Worker也同步更新，它就发挥作用了。 我们看以下官方提供的示例 lua_shared_dict process_events 1m; init_worker_by_lua_block { local ev = require &quot;resty.worker.events&quot; local handler = function(data, event, source, pid) print(&quot;received event; source=&quot;,source, &quot;, event=&quot;,event, &quot;, data=&quot;, tostring(data), &quot;, from process &quot;,pid) end ev.register(handler) local ok, err = ev.configure { shm = &quot;process_events&quot;, -- defined by &quot;lua_shared_dict&quot; timeout = 2, -- life time of unique event data in shm interval = 1, -- poll interval (seconds) wait_interval = 0.010, -- wait before retry fetching event data wait_max = 0.5, -- max wait time before discarding event shm_retries = 999, -- retries for shm fragmentation (no memory) } if not ok then ngx.log(ngx.ERR, &quot;failed to start event system: &quot;, err) return end } 在init_worker_by_lua_block阶段初始化，是因为它需要在每个Worker中都运行，便于同步到其他进程，其他的就是一些配置参数问题。 下面我们把它结合上面的缓存模块一起使用。 lua-resty-mlcache提供了ipc接口来支持lua-resty-worker-events模块，我们直接配置参数即可。 lua_shared_dict cache_dict 1m; lua_shared_dict cache_lock 1m; lua_shared_dict worker_events 1m; init_worker_by_lua_block { local mlcache = require &quot;resty.mlcache&quot; local worker_events = require &quot;resty.worker.events&quot; local ok, err = worker_events.configure { shm = &quot;worker_events&quot;, timeout = 2, interval = 1, wait_interval = 0.010, wait_max = 0.5, shm_retries = 999, } local cache, err = mlcache.new(&quot;my_cache&quot;, &quot;cache_dict&quot;, { lru_size = 500, -- size of the L1 (Lua VM) cache ttl = 3600, -- 1h ttl for hits neg_ttl = 30, -- 30s ttl for misses shm_locks = &quot;cache_lock&quot;, resty_lock_opts = { exptime = 10, timeout = 5 }, ipc = { register_listeners = function(events) for _, event_t in pairs(events) do worker_events.register( function(data) event_t.handler(data) end, channel_name, event_t.channel ) end end, broadcast = function(channel, data) worker_events.post(channel_name, channel, data) end } }) if err then end } 以上ipc部分代码截取自Kong项目，有兴趣也可以去参考一下它的设计模式。 ","tags":[{"index":-1,"name":"openresty","slug":"openresty","used":true,"link":"https://xwl.io/tag/openresty/"}],"title":"OpenResty Worker缓存","feature":"","link":"https://xwl.io/post/openresty-worker-cache/","stats":{"text":"6 min read","time":306000,"words":1140,"minutes":6},"date":"2021-05-25 00:03:17","dateFormat":"2021-05-25"},{"content":"全局配置 worker_processes auto; 启动工作进程的数量，auto代表服务器有多少核心，就启动多少个进程。 worker_rlimit_nofile 20480 工作进程最大打开的文件数，同Linux概念中的ulimit -n 20480 worker_rlimit_core 500M; 表示工作进程所使用的Core文件大小的最大值。 进程在Crash的时候会产生Core文件，可供后续获取更详细的调试信息。 worker_shutdown_timeout 3; 当安全结束一个工作进程时，会停止对工作进程分配新连接，并等待他处理完当前的任务后再退出，如果设置了超时时间，超时后nginx会强制关闭工作进程的连接。 event配置 accept_mutex off; 这个配置默认是开启的，高并发模式下，关闭它会提升一定的QPS。 当一个新连接到达时，如果激活了accept_mutex，那么多个Worker将以串行方式来处理，其中有一个Worker会被唤醒，其他的Worker继续保持休眠状态； 如果没有激活accept_mutex，那么所有的Worker都会被唤醒，不过只有一个Worker能获取新连接，其它的Worker会重新进入休眠状态，这就是「惊群问题」。 从系统的层面上来说，也就是进程之间会产生一定数量的上下文切换，但我们的工作进程一般与CPU相关，并不会有特别多的进程，所以建议关闭。 另外nginx从1.11.3版本之后也增加了对NGX_EXCLUSIVE_EVENT选项的支持，这样就可以避免多worker的epoll出现的惊群效应，从此之后accept_mutex从默认的on变成了默认off。 worker_connections 20480; 这个参数就是工作进程最大支持的连接数，理论上是越多越好，但也会受最大可打开的文件数限制，也就是需要和worker_rlimit_nofile参数保持一致即可。 http配置 server_tokens off; 隐藏nginx版本号。 client_max_body_size 0 设置nginx上传文件的大小，一般会设置为0，也就是不限制。 后续我们可以在程序中灵活的进行判断。 open_file_cache max=1000 inactive=60; 缓存打开的文件描述符，max指缓存的最大数量，inactive则指缓存文件多久没有活跃则移除，这是一个优化参数。 access_log logs/access.log main buffer=30000 flush=3; 这是一个日志写入优化参数。 在高并发环境下，每秒都会产生大量的日志，产生一条日志数据就写一条，会产生大量不必要的IO损耗。 buffer指缓存区大小，如果数据超过缓冲区大小的，会把数据写入磁盘。 flush指间隔多少秒，就写入一次磁盘。 以上条件满足任何一点，都会产生写入操作。 上游服务长连接 让上游服务支持以HTTP1.1协议发送请求，同时支持Keep-alive，也就是所谓的长连接。 http { upstream backend { server 0.0.0.1; balancer_by_lua_block { edge.balancer_phase() } keepalive 300; } server { listen 80; listen 443 ssl; location / { set $upstream_connection ''; proxy_http_version 1.1; proxy_set_header Connection $upstream_connection; } } } ","tags":[{"index":-1,"name":"openresty","slug":"openresty","used":true,"link":"https://xwl.io/tag/openresty/"}],"title":"OpenResty 中的 Nginx 配置文件详解","feature":"","link":"https://xwl.io/post/openresty-nginx-configure/","stats":{"text":"3 min read","time":168000,"words":761,"minutes":3},"date":"2021-05-20 23:10:37","dateFormat":"2021-05-20"},{"content":"学习需要有一个好的策略，靠意志力学习是的非常痛苦的。 怎样才能快乐有效地学习？我们要做到三点 自己喜欢的东西 能够学得好、让自己有成就感 这种学习能给我们带来价值 基于这三点，在学习过程中，需要注意以下四个方面： 按需学习 选择对我们有用、与历史过往经历匹配、能让我们参与其中、并能够应用的学习内容。长期有用的东西，需要转化成短期有用；一个大的学习内容，需要拆分出对我们最有用的部分，并集中学习这个部分即可。 在选择学习内容的时候，我们需要遵循的原则是 有用：对我们现阶段要有用的，这个用处不一定是工作或者赚钱，也可以是让人放松等等； 匹配：跟我们的经验背景相匹配的，不会太粗浅，也不会太深奥； 参与：能够有参与感的，说教式的学习最好不要参与； 应用：可以应用到行动中去的，跟我们的工作、生活相结合的。 调整心态 不要试图用意志力坚持学习，而要从学习本身寻求快乐。把诱惑隔离开，渐渐将学习养成习惯。学习一样东西，不需要1万小时， 20小时足矣。 提升元认知策略 每个人的认知方式不同，知道自己的认知优劣势，才能够制定适合自己的学习方法。 总结与反思学习风格，发现自己的优势与劣势，是学习当中，除内容选择外，更需要关注的事情。 正确犯错 我们不可能永远不犯错。 每一次犯错，都是在学习中进步，都是成长的机会。 每次犯错后如果能够找到原因，并在下次有所进步，那么在犯错中感受到的就是快乐，而非挫败。 人类的大脑是从犯错中学习的，能否从犯错中进步，决定了犯错这件事获得的是成就感还是挫败感。 总结 学习过程通常有三层： 知识层：学习某项内容，会某个知识点； 能力层：超越具体的学习内容，举一反三，应用到解决问题中； 价值观层：建立整体的心智模型和价值体系。 知识层次的学习，需要的更多是原理性或资讯类的东西；而能力层次的学习，需要的是程序性或者操作类的东西。 参考 靠意志力的学习都是耍流氓 ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://xwl.io/tag/personal-growth/"}],"title":"高效学习的正确方法","feature":"","link":"https://xwl.io/post/learning-method/","stats":{"text":"3 min read","time":137000,"words":688,"minutes":3},"date":"2021-05-19 00:16:53","dateFormat":"2021-05-19"},{"content":"在Python ORM的选型过程中，我们经常会拿Peewee和SQLAlchemy进行对比。 从功能的全面与强大而言，在大型项目中，肯定优先选择SQLAlchemy。作为运维而言，大多都是中小型项目居多，Peewee作为轻量级的ORM，使用也非常简单，自然作为首选了。 下面介绍了大致的使用方式。 创建数据库连接 直接创建连接 from peewee import MySQLDatabase db = MySQLDatabase( 'database_name', user='root', password='secret', host='db.xwl.io', charset='utf8mb4') 当然我们更多的是配合连接池使用 from playhouse.pool import PooledMySQLDatabase db = PooledMySQLDatabase( 'database_name', max_connections=8, stale_timeout=300, user='root') class BaseModel(Model): class Meta: database = db 创建模型表 通常的做法是定义一个公共的Model，用于存储公共的字段和方法。 import datetime from peewee import Model, DateTimeField, IntegerField class BaseModel(Model): create_time = DateTimeField(default=datetime.datetime.now) update_time = DateTimeField(default=datetime.datetime.now) deleted = IntegerField() def save(self, *args, **kwargs): self.update_time = datetime.datetime.now() return super(BaseModel, self).save(*args, **kwargs) class Meta: database = db 在SQLAlchemy中，在定义字段的时候，可以使用onupdate关键字，在Peewee的模块中可没有这个功能过，于是我们重构的save方法。 除此之外，其实还有一些公共的字段，比如主键id、操作用户等，也可以放置于BaseModel中。 我们尝试创建一个用户表： from peewee import AutoField, CharField class User(BaseModel): class Meta: table_name = 'user' id = AutoField() username = CharField(max_length=32) 修改内置的table_name字段可以定义创建表结构时使用的表名称，AutoField的意思是一个自增的主键ID，CharField在MySQL中就是varchar，max_length就是定义该字段的最大长度。 字段类型表如下图所示 创建表也非常简单 db.create_tables([User]) 默认情况下，peewee包括 IF NOT EXISTS 创建表时使用子句。 存储与检索数据 增 添加一行数据 user = User(username=&quot;xwl&quot;) user.save() 或者可以使用一段JSON格式的数据 data = {&quot;username&quot;: &quot;xwl&quot;} user = User(**data) user.save() 删 User.delete().where(User.id == 1).execute() 改 User.update(username=&quot;xwl-2&quot;).where(User.id == 1).execute() 查 查询数据的基本格式是这样 select_queries = User.select(...).where(...).order_by(...).limit(...)... 就跟SQL的使用差不多，按需使用即可，更多内容的参考官方文档。 运维应用也就拿来做做管理后台，以上基本就能满足绝大多数场景，也不建议用的太过于复杂，维护起来会很痛苦。 参考 Peewee 官方文档 Peewee 中文文档 ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"Python Peewee 使用","feature":"","link":"https://xwl.io/post/python-peewee/","stats":{"text":"3 min read","time":152000,"words":610,"minutes":3},"date":"2021-05-17 21:04:54","dateFormat":"2021-05-17"},{"content":"我们对于域名的管理，主要需要监控的状态包括域名过期时间、域名的证书过期时间，就简单介绍一下。 通常会在阿里云，或者腾讯云这类主流平台购买域名和证书，通常都会有相关的API接口可供查询，这里就不介绍相关SDK的使用了。 我们使用更加通用的方式来监控域名，获取其相关信息。 查询域名过期时间 就非常简单的示例，先安装依赖包 pip install whois 示例代码 import whois domain = whois.query(&quot;xwl.io&quot;) print(domain.__dict__) print(domain.expiration_date) 我们可以打印出所有支持的字段信息，以下是相关输出，根据需求获取即可。 &gt;&gt;&gt; print(domain.__dict__) { 'name': 'xwl.io', 'registrar': 'CloudFlare, Inc.', 'registrant_country': 'CN', 'creation_date': datetime.datetime(2021, 1, 30, 15, 54, 49), 'expiration_date': datetime.datetime(2023, 1, 30, 15, 54, 49), 'last_updated': datetime.datetime(2021, 5, 3, 21, 17, 4), 'status': 'clientTransferProhibited https://icann.org/epp#clientTransferProhibited', 'statuses': ['serverTransferProhibited https://icann.org/epp#serverTransferProhibited', 'clientTransferProhibited https://icann.org/epp#clientTransferProhibited'], 'dnssec': False, 'name_servers': {'ashley.ns.cloudflare.com\\r', 'earl.ns.cloudflare.com\\r'}, 'registrant': 'DATA REDACTED' } 查询域名证书过期时间 安装依赖包 pip install pyopenssl python-dateutil 以下是获取域名证书过期时间的示例脚本 import ssl import time import OpenSSL from dateutil import parser hostname = 'blog.xwl.io' port = 443 cert = ssl.get_server_certificate((hostname, port)).encode() cert_obj = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM, cert) cert_expire_time = parser.parse(cert.get_notAfter().decode(&quot;UTF-8&quot;)).strftime('%Y-%m-%d %H:%M:%S') print(cert.has_expired()) print(cert_expire_time) 输出信息如下： False 2022-05-07 23:59:59 由于我的网站挂在CloudFlare下，这个过程中也可能会出现一个错误 ssl.SSLError: [SSL: SSLV3_ALERT_HANDSHAKE_FAILURE] sslv3 alert handshake failure (_ssl.c:1122) 这是因为请求的时候没有传递主机名导致的，需要修改ssl模块如下 def get_server_certificate(addr, ssl_version=PROTOCOL_TLS, ca_certs=None): &quot;&quot;&quot;Retrieve the certificate from the server at the specified address, and return it as a PEM-encoded string. If 'ca_certs' is specified, validate the server cert against it. If 'ssl_version' is specified, use it in the connection attempt.&quot;&quot;&quot; host, port = addr if ca_certs is not None: cert_reqs = CERT_REQUIRED else: cert_reqs = CERT_NONE context = _create_stdlib_context(ssl_version, cert_reqs=cert_reqs, cafile=ca_certs) with create_connection(addr) as sock: with context.wrap_socket(sock, server_hostname=host) as sslsock: dercert = sslsock.getpeercert(True) return DER_cert_to_PEM_cert(dercert) 主要就是为这一行with context.wrap_socket(sock, server_hostname=host) as sslsock:，加上server_hostname字段。 ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"Python 监控域名信息","feature":"","link":"https://xwl.io/post/uTLx54AFk/","stats":{"text":"3 min read","time":157000,"words":549,"minutes":3},"date":"2021-05-15 22:26:51","dateFormat":"2021-05-15"},{"content":"有句话说的好，职场中，不要总是埋头苦干，要懂得表现自己！ 当年我也是想着，只要自己有工作能力，而且自己足够的努力，老板就一定能发现。 这种单纯的想法一直伴随了我几年，后来我才发现，酒香也怕巷子深，我们时刻要学会自我营销。 为什么需要汇报工作 展现自己的工作能力 日常工作中你需要及时汇报，将你的工作成果展现给领导，让他知道你能担当大任。 领导有掌控感，对你更放心 我们有时候很难接受，觉得老板为什么三天两头问我工作如何了，但想象一下等外卖，其实就可以理解，所以你需要转变心态，主动汇报。 让上司获得掌控感，他会对你放心，也更信任你的工作能力。 任何一个上司都比较看重两样东西：一是他的上司对他的信任；二是他的下属对他的尊重。 而上下级的信任和尊重，靠的就是及时的汇报工作！ 怎样汇报工作 以下是汇报工作常见的三个场景，对号入座即可。 突然提问 - 如何化被动为主动 关键的5秒钟 认可对方的提问 澄清对方的问题，为自己争取思考的时间。 思路 认可对方提问 我正准备向你汇报呢，您问的太及时了 确认对方问题 你说的这期XX活动目前已经完成70% 详细汇报接下来的任务 接下来我要XXX做，采取XXX方法，预计XXX时候就可以完成， 前期确实遇到了XXX问题，但是我做了XXX，这个项目目前进展顺利 汇报问题 - 给出解决方案别忘记 遇到了我们解决不了的，或者不再我们计划内的事情，正确的方法应该是带着解决方案去汇报。 解决方案最好有2个，要让老板做选择题 目前出现的问题 阐述发生问题的原因 给出你认为可行的解决方案 思路 问题原因：老板，这周五的活动嘉宾方面出了点小问题。我按计划邀请了A嘉宾，他也的确答应了。但刚收到微信消息，他说临时有事无法到场。 解决方案供老板选择：目前有2种可行解决方案。 现在去尝试邀请大咖B，代替A嘉宾 重新调整活动策划，把涉及到A嘉宾的部分都修改掉。您觉得哪个更合适呢？ 这样说，基本上你的汇报就达到了90分，如果升级一下思维，你还可以站在老板的角度，对这两个方案做利弊分析，帮助老板更好地决策。比如，你可以继续补充： 方案1的话，临时找，时间上很紧张，需要您出面去邀请。万一他也没有答应，我们就很被动了。 方案2的话，整体变化大，各团队都要同步信息共同应对。 最后把决定权交给领导，领导会以比你更高的眼光或者从他的角度指示你去按照哪种方法去做。 解决方案最好有2个，要让老板做选择题 汇报成果 - 多用数据和讲故事的方法 汇报成果往往是在一个项目或一个任务结束后进行。 那怎么才能让成果汇报出彩呢？ 我的建议是使用关键数据和故事，数据是理性呈现，故事是感性打动，只有理性和感性相结合，才能给人留下深刻印象。 参考 领导为什么不喜欢提拔老实人？这是我听过最醍醐灌顶的答案。 ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://xwl.io/tag/personal-growth/"}],"title":"职场人如何汇报工作","feature":"","link":"https://xwl.io/post/MiZtYXF53/","stats":{"text":"4 min read","time":201000,"words":995,"minutes":4},"date":"2021-05-14 00:55:11","dateFormat":"2021-05-14"},{"content":" 以下内容来源于网络 AES简介 AES加密是建立在DES加密不能满足破解难度而产生的。由比利时两位非常著名的密码学家Joan Daemen和Vincent Rijmen设计，选取了分组长度为128byte，密钥长度为128byte、192byte和byte比特的三个版本。 分组密码有五种工作体制： 电码本模式Electronic Codebook Book (ECB) 密码分组链接模式Cipher Block Chaining (CBC) 计算器模式Counter (CTR) 密码反馈模式Cipher FeedBack (CFB) 输出反馈模式Output FeedBack (OFB) CBC模式 优点： 不容易主动攻击,安全性好于ECB,适合传输长度长的报文,是SSL、IPSec的标准。 缺点： 不利于并行计算； 误差传递； 需要初始化向量IV 以下是代码示例： #!/usr/bin/python3 # -*- coding: utf-8 -*- import logging import base64 import hashlib import binascii from Crypto.Cipher import AES class AESCrypt: &quot;&quot;&quot; AES/CBC/PKCS5Padding 加密 &quot;&quot;&quot; def __init__(self, key): &quot;&quot;&quot; 使用密钥,加密模式进行初始化 :param key: &quot;&quot;&quot; if len(key) != 16: raise RuntimeError('密钥长度非16位!!!') self.key = str.encode(key) self.iv = bytes(16) self.MODE = AES.MODE_CBC self.block_size = 16 # 填充函数 # self.padding = lambda data: data + (self.block_size - len(data) % self.block_size) * chr(self.block_size - len(data) % self.block_size) # 此处为一坑,需要现将data转换为byte再来做填充，否则中文特殊字符等会报错 self.padding = lambda data: data + (self.block_size - len(data.encode('utf-8')) % self.block_size) * chr(self.block_size - len(data.encode('utf-8')) % self.block_size) # 截断函数 self.unpadding = lambda data: data[:-ord(data[-1])] def aes_encrypt(self, plaintext): &quot;&quot;&quot; 加密 :param plaintext: 明文 :return: &quot;&quot;&quot; try: # 填充16位 padding_text = self.padding(plaintext).encode(&quot;utf-8&quot;) # 初始化加密器 cryptor = AES.new(self.key, self.MODE, self.iv) # 进行AES加密 encrypt_aes = cryptor.encrypt(padding_text) # 进行BASE64转码 encrypt_text = (base64.b64encode(encrypt_aes)).decode() return encrypt_text except Exception as e: logging.exception(e) def aes_decrypt(self, ciphertext): &quot;&quot;&quot; 解密 :param ciphertext: 密文 :return: &quot;&quot;&quot; try: # 密文必须是16byte的整数倍 # if len(ciphertext) % 16 != 0: # raise binascii.Error('密文错误!') cryptor = AES.new(self.key, self.MODE, self.iv) # 进行BASE64转码 plain_base64 = base64.b64decode(ciphertext) # 进行ASE解密 decrypt_text = cryptor.decrypt(plain_base64) # 截取 plain_text = self.unpadding(decrypt_text.decode(&quot;utf-8&quot;)) return plain_text except UnicodeDecodeError as e: logging.error('解密失败,请检查密钥是否正确!') logging.exception(e) except binascii.Error as e: logging.exception(e) except Exception as e: logging.exception(e) if __name__ == '__main__': # 测试 cryptor = AESCrypt('ZGJfXxZNGPqWAC53') aes_encrypt_str = cryptor.aes_encrypt('原谅我个渣渣!!!') print(f'加密结果为: {aes_encrypt_str}') aes_decrypt_str = cryptor.aes_decrypt('KMpLeX7zYGc3SBZi55/BR0VnMybZb29CrFJFl3ac8/k=') print(f'解密结果为: {aes_decrypt_str}') 遇到的问题 key，data，iv未转byte报错 TypeError: Object type &lt;class 'str'&gt; cannot be passed to C code 解决方案 key，data，iv均需要转为byte类型 key = str.encode(key) iv = bytes(16) text = text.encode(&quot;utf-8&quot;) 中文/特殊字符加密报错 ValueError: Data must be padded to 16 byte boundary in CBC mode。 解决方案：现将data转成字节之后在进行填充，始终可保证字节数为16byte的整数倍 self.padding = lambda data: data + (block_size - len(data.encode('utf-8')) % block_size) * chr(block_size - len(data.encode('utf-8')) % block_size) 密文修改后，不是16byte的整数倍，返回填充错误 return binascii.a2b_base64(s) binascii.Error: Incorrect padding 解决方案：提前检查密文长度抛出异常或者直接进行异常捕获 binascii.Error # 密文必须是16byte的整数倍 if len(ciphertext) % 16 != 0: raise binascii.Error('密文错误!') ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"Python AES/CBC/PKCS5Padding 加解密","feature":"","link":"https://xwl.io/post/NYZgYN2ak/","stats":{"text":"4 min read","time":227000,"words":804,"minutes":4},"date":"2021-05-13 00:00:17","dateFormat":"2021-05-13"},{"content":"该项目的目录结构如下 backend/ frontend/ backend 目录是后端的 Python 应用，用于给Vue提供相关的API服务 frontend 目录就是一个Vue应用 使用vue init webpack frontend，初始化Vue项目目录。 在frontend中执行npm run build，会构建编译生成一个dist目录，就是其相关的静态文件组，以下我们来展示一下如何应用。 在backend目录中，初始化Tornado Web，直接从官方扒下来的示例 import tornado.ioloop import tornado.web class MainHandler(tornado.web.RequestHandler): def get(self): self.write(&quot;Hello, world&quot;) def make_app(): return tornado.web.Application([ (r&quot;/&quot;, MainHandler), ]) if __name__ == &quot;__main__&quot;: app = make_app() app.listen(8888) tornado.ioloop.IOLoop.current().start() 关于Vue相关的静态文件处理，就是要在Tornado Web中的路由部分，引用其构建编译生成的静态文件。 import os def make_app(): current_path = os.path.dirname(__file__) return tornado.web.Application([ (r&quot;/api/index&quot;, MainHandler), (r'^/()$', StaticFileHandler, {&quot;path&quot;:os.path.join(current_path, &quot;frontend/dist&quot;), &quot;default_filename&quot;:&quot;index.html&quot;}), (r'^/(.*)$', StaticFileHandler, {&quot;path&quot;:os.path.join(current_path, &quot;frontend/dist&quot;)} )], 脚本参数说明 其中current_path变量指向该项目的根目录 通过路由的default_filename参数，指定该条记录默认的访问的HTML路径 以上配置就能将Tornado和Vue部署在同一个服务中。 接下来就有另一个问题，我们不可能在开发过程中，每次都构建之后，再重新运行Python服务，那是很痛苦的，所以我们准备在Vue开发环境服务中配置跨域，然后两个服务各自监听端口，进行联调测试。 我们编辑配置frontend/config/index.js，找到proxyTable字段，修改如下： proxyTable: { '/api': { target: 'http://127.0.0.1:8888/', }, }, 其中target字段就是我们运行的Tornado服务，我们在Vue项目中访问路径/api/index，即可调用之前预设的HelloWorld接口。 ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"Python Vue 部署与联调测试","feature":"","link":"https://xwl.io/post/9LRClFOn3/","stats":{"text":"2 min read","time":117000,"words":463,"minutes":2},"date":"2021-05-11 23:49:50","dateFormat":"2021-05-11"},{"content":"在开发运维平台的时候，都有绕不过的一个需求，那就是对网站证书的管理。 我们需要对证书进行集中化管理，包括颁发证书、解析证书，甚至要定时分析是否有证书过期需要即时续费等，给管理人员一个直观的展示。 首先安装依赖模块，pyopenssl用于证书解析和python-dateutil模块用于日期解析，使用pip直接安装即可。 pip install pyopenssl python-dateutil 生成证书脚本 from OpenSSL import crypto k = crypto.PKey() k.generate_key(crypto.TYPE_RSA, 2048) # generate RSA key-pair cert = crypto.X509() cert.get_subject().C = &quot;CN&quot; cert.get_subject().O = &quot;XWL, Inc.&quot; cert.get_subject().OU = &quot;XWL&quot; cert.get_subject().CN = &quot;xwl.io&quot; cert.set_serial_number(1000) cert.gmtime_adj_notBefore(0) cert.gmtime_adj_notAfter(10*365*24*60*60) cert.set_issuer(cert.get_subject()) cert.set_pubkey(k) cert.sign(k, 'sha256') open(&quot;selfsign.crt&quot;, 'wb').write(crypto.dump_certificate(crypto.FILETYPE_PEM, cert)) open(&quot;private.key&quot;, 'wb').write(crypto.dump_privatekey(crypto.FILETYPE_PEM, k)) 直接使用刚刚生成的证书进行解析，具体注释下脚本输出内容中已有说明。 import OpenSSL import time from dateutil import parser cert = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM, open(&quot;selfsign.crt&quot;).read()) certIssue = cert.get_issuer() print (&quot;证书版本: &quot;,cert.get_version() + 1) print (&quot;证书序列号: &quot;,hex(cert.get_serial_number())) print (&quot;证书中使用的签名算法: &quot;,cert.get_signature_algorithm().decode(&quot;UTF-8&quot;)) print (&quot;颁发者: &quot;,certIssue.commonName) datetime_struct = parser.parse(cert.get_notBefore().decode(&quot;UTF-8&quot;)) print (&quot;有效期从: &quot;,datetime_struct.strftime('%Y-%m-%d %H:%M:%S')) datetime_struct = parser.parse(cert.get_notAfter().decode(&quot;UTF-8&quot;)) print (&quot;到: &quot;,datetime_struct.strftime('%Y-%m-%d %H:%M:%S')) print (&quot;证书是否已经过期: &quot;,cert.has_expired()) print(&quot;公钥长度&quot; ,cert.get_pubkey().bits()) print(&quot;公钥:\\n&quot; ,OpenSSL.crypto.dump_publickey(OpenSSL.crypto.FILETYPE_PEM, cert.get_pubkey()).decode(&quot;utf-8&quot;)) print(&quot;主体信息:&quot;) print(&quot;CN : 通用名称 OU : 机构单元名称&quot;) print(&quot;O : 机构名 L : 地理位置&quot;) print(&quot;S : 州/省名 C : 国名&quot;) for item in certIssue.get_components(): print(item[0].decode(&quot;utf-8&quot;), &quot; —— &quot;,item[1].decode(&quot;utf-8&quot;)) print(cert.get_extension_count()) subject = cert.get_subject() print(&quot;域名:\\n&quot; ，subject.CN) 通常在接收到用户上传的证书之后，也会对其进行可用性校验，防止误传。 import OpenSSL with open(&quot;selfsign.crt&quot;) as f: crt = f.read() with open(&quot;private.key&quot;) as f: key = f.read() try: private_key_obj = OpenSSL.crypto.load_privatekey(OpenSSL.crypto.FILETYPE_PEM, private_key) except OpenSSL.crypto.Error: raise Exception('private key is not correct: %s' % private_key) try: cert_obj = OpenSSL.crypto.load_certificate(OpenSSL.crypto.FILETYPE_PEM, cert) except OpenSSL.crypto.Error: raise Exception('certificate is not correct: %s' % cert) context = OpenSSL.SSL.Context(OpenSSL.SSL.TLSv1_METHOD) context.use_privatekey(private_key_obj) context.use_certificate(cert_obj) try: context.check_privatekey() print(&quot;ok&quot;) except OpenSSL.SSL.Error: print(&quot;error&quot;) 以上就是我们常用的证书管理的操作，以及获取常用证书信息的方法。 ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"Python 证书管理","feature":"","link":"https://xwl.io/post/Aqi_GBQPM/","stats":{"text":"4 min read","time":195000,"words":653,"minutes":4},"date":"2021-05-11 00:01:44","dateFormat":"2021-05-11"},{"content":"都2021年了，个人博客都成为小众产品了，几乎都是开发者，十有八九还是个前端开发。 虽然GitHub时常被墙，但大部分人还是会选择GitHub Pages，以减少服务器的维护成本。 而作为个人博客站长，几乎都会不务正业的折腾各种功能模块，今天就来介绍SEO相关，关于网站收录的部分。 常用的搜索引擎一般分为以下三种： 百度 Google Bing 百度作为检索信息最多，且最乱的典型代表，你常常会在第一页找不到你想要的结果，但无奈它是我国最常用的搜索引擎。 常规的提交方法是去百度站长平台提交Sitemap，文件名一般为sitemap.xml，由于我目前使用的Gridea，没有生成Sitemap的方法，于是乎决定采用API的方式提交。 我们先准备好推送网站收录的脚本，以下是我写好的.push.py import re import json import requests domain = &quot;blog.xwl.io&quot; token = &quot;xxxxxxxxxx&quot; res = requests.get(&quot;https://%s/archives/&quot; % domain) tags = re.findall(r'href=&quot;([a-zA-z]+://[^\\s]*)&quot;', str(res.text)) urls = [] for t in tags: if t.endswith(&quot;css&quot;) or t.endswith(&quot;js&quot;):continue if not t.startswith(domain):continue urls.append(t) urls = &quot;\\n&quot;.join(urls) headers = {&quot;Content-Type&quot;: &quot;text/plain&quot;} resp = requests.post(&quot;http://data.zz.baidu.com/urls?site=https://%s&amp;token=%s&quot; &amp; (domain, token), headers=headers, data=urls) print(resp.text) 该脚本的功能是抓取网页上的所有链接，目标页面一般是首页，或者归档页，然后通过百度提供的API进行提交。 另外有两个值得注意的地方： 脚本中的token在百度站长平台内的普通收录里获取。 百度之前有个自动提交的JS，据我所知目前已经作废了，但接口还会正常返回。 然后我们进入到Github的博客项目中，选择Action，创建一个Workflow，会生成一个基础的模版，然后直接在steps路径下执行自己的脚本。 # This is a basic workflow to help you get started with Actions name: CI # Controls when the action will run. on: # Triggers the workflow on push or pull request events but only for the main branch push: branches: [ main ] pull_request: branches: [ main ] # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # A workflow run is made up of one or more jobs that can run sequentially or in parallel jobs: # This workflow contains a single job called &quot;build&quot; build: # The type of runner that the job will run on runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 - name: update baidu uses: actions/setup-python@v2 with: python-version: '3.x' # Version range or exact version of a Python version to use, using SemVer's version range syntax architecture: 'x64' # optional x64 or x86. Defaults to x64 if not specified - run: pip install requests &amp;&amp; python .push.py 以上是我使用的完整的workflow配置，再添加上Google和Bing的部分，就大功告成了。 Google和Bing的Sitemap提交就非常的简单，直接通过一个GET请求即可。 在配置中的steps字段下继续增加即可。 - name: update google uses: wei/curl@master with: args: https://www.google.com/ping?sitemap=https://blog.xwl.io/atom.xml - name: update bing uses: wei/curl@master with: args: http://www.bing.com/webmaster/ping.aspx?sitemap=https://blog.xwl.io/atom.xml 把自己的小站弄的花里胡哨，除了知识的分享，也是希望更多的人能看到。 ","tags":[{"index":-1,"name":"github","slug":"github","used":true,"link":"https://xwl.io/tag/github/"},{"index":-1,"name":"ci","slug":"ci","used":true,"link":"https://xwl.io/tag/ci/"},{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"使用GitHub Action自动提交网站收录","feature":"","link":"https://xwl.io/post/Qc51rd-j-/","stats":{"text":"4 min read","time":231000,"words":843,"minutes":4},"date":"2021-05-09 01:36:11","dateFormat":"2021-05-09"},{"content":"正好今晚处理了博客的SEO问题，配置了一下GitHub Action，就顺便回顾一下GitLab CI常用的策略吧。 背景 GitHub是一款非常优秀的产品，但企业还是更倾向于在内部自建仓库，所以在运维流程上，还是接触的GitLab稍多一些。 我刚来的时候公司运维环节比较薄弱，所以还是沿用之前的GitLab CI/CD流程，故学习了一阵，如果你们还没有完善的CI/CD流程，建议使用Jenkins。 简介 在GitLab CI上常用的动作 单元测试，跑完之后会有个测试覆盖率，部分企业会作为发布的硬性标准。 质量评估，可能会运行语法检测，或者集成一些第三方的代码质量管理平台，例如Sonar 打包容器，现在是云原生时代，建议使用，更多的应该关注业务本身，不应该过多的把时间花在重复配置环境上。 至于部署？ 实际生产上，从来都不会把部署的工作放到GitLab上做，不可控因素太多了。 除非就几个人的创业公司，为了省事，可以这样做。 言归正传，我们先看下完整的构建配置.gitlab-ci.yml stages: - unitest - qa - build variables: Name: example before_script: - echo &quot;run script&quot; job-unitest: stage: unitest job-qa: stage: qa job-build: stage: build 相比乱七八糟的教程，常用的就这么几种 stages，定义这个构建有几个流程，会按顺序执行下去，分别对应的job的stage字段 variables，定义环境变量，在之后的流程中可以引用它。 before_script，流程开始前，执行的准备工作，可以完成一些配置性的工作。 job-xxx，这个名字是可以随意定义的，只要stage字段匹配即可。 单元测试流程 也就是我们介绍的stage: unitest阶段，名称为job-unitest，可以随意定义。 拿Python举例，常用的方案会使用pytest进行单元测试工作，同时生成一个测试报告。 job-unitest: stage: unitest tags: - docker image: python:3 script: - pytest --junit-xml=report.xml 额外介绍一些tags，它的可选项一般为shell和docker作为它的Runner，建议使用后者，需要在编译Runner的时候集成docker。 shell模式的问题：会直接用Runner宿主机的shell命令，在多Runner环境下，要保证每台机器都要配置依赖环境，非常麻烦。 同时在以后的Runner升级工作中，可能会有未知的风险。 另外一种场景是，应用可能依赖数据库，那么配置就会变成这样。 job-unitest: stage: unitest tags: - docker image: python:3 services: - mysql:5.7 script: - pytest --junit-xml=report.xml 使用数据库的官方文档 GitLab CI MySQL 需要注意的是，MySQL的User字段可能为root，官方文档显示的是runner，注意对应版本。 友情提示：不会真有人忘记创建DB吧？ 容器打包流程 这个阶段没什么好说的，无外乎使用Dockerfile，进行build、push工作，直接给个范例。 job-bulid: stage: build tags: - docker services: - docker:dind image: docker:latest script: - docker build -t ${Name}:1.0 . - docker push 这里唯一要注意的，只有docker:dind这个服务，它是必须要存在的，否则会报错。 还记得之前我们定义过一个变量，这里就用上了。 push的命令我没有补全，自行查找文档。 睡了 狗命要紧。 ","tags":[{"index":-1,"name":"gitlab","slug":"gitlab","used":true,"link":"https://xwl.io/tag/gitlab/"},{"index":-1,"name":"ci","slug":"ci","used":true,"link":"https://xwl.io/tag/ci/"},{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"关于GitLab CI常用策略","feature":"","link":"https://xwl.io/post/okYjMtPcs/","stats":{"text":"4 min read","time":196000,"words":869,"minutes":4},"date":"2021-05-07 00:56:33","dateFormat":"2021-05-07"},{"content":"环境：Windows/Python 2 由于维护一些历史的.net项目，还运行在Windows平台上，在项目构建，甚至代码发布的过程中，需要解决一些技术债务问题。 Jinkens 我们采用的Windows下的Jenkins编译.net framework项目，在此过程中，该项目存在多个中文的文件名称，由于该项目有十几年历史，结构复杂不便改动，于是只能想法办兼容一下。 使用git获取差异文件列表 git diff --no-renames --name-only $commit_id_1 $commit_id_2 对比历史差异文件的时候，需提前执行以下命令，否则会造成中文乱码 git config --global core.quotepath false 然后我们在python脚本中处理文件名编码格式，由于是Windows平台，所以采用gbk编码。 filename.decode(&quot;utf-8&quot;).encode(&quot;gbk&quot;) Python 此外在python中使用zipfile模块进行压缩文件处理的时候，也要注意中文乱码问题 import zipfile zf = InMemoryZip('code.zip') p = InMemoryZip() for name in zf.get_namelist(): try: n = name.encode('cp437').decode('gbk') except: n = name.encode('utf-8').decode('utf-8') p.append(n, zf.open(name)) 在内存中操作ZIP压缩文件（附注代码） import os import io import zipfile class InMemoryZip(object): def __init__(self, buffer=None): # Create the in-memory file-like object self.in_memory_zip = io.BytesIO(buffer) if buffer: self.zf = zipfile.ZipFile(self.in_memory_zip, &quot;r&quot;) else: self.zf = zipfile.ZipFile(self.in_memory_zip, &quot;a&quot;, zipfile.ZIP_DEFLATED, False) def append(self, filename, file_contents): # Write the file to the in-memory zip # zf.writestr(filename_in_zip, file_contents) self.zf.writestr(filename, file_contents) # Mark the files as having been created on Windows so that # Unix permissions are not inferred as 0000 for zfile in self.zf.filelist: zfile.create_system = 0 return self def read_file(self, name): return self.zf.open(name).read() def extractall(self, directory): self.zf.extractall(directory) def get_namelist(self): return self.zf.namelist() def read(self): &quot;&quot;&quot;Returns a string with the contents of the in-memory zip.&quot;&quot;&quot; self.zf.close() self.in_memory_zip.seek(0) return self.in_memory_zip.read() ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"Python 2的中文编码问题","feature":"","link":"https://xwl.io/post/Fml9VHfUQ/","stats":{"text":"3 min read","time":130000,"words":449,"minutes":3},"date":"2021-05-05 00:27:06","dateFormat":"2021-05-05"},{"content":"测试的概念 以下只是为了让大家更快的熟悉整个测试体系，不用过度区分概念是否严谨。 总体可分为 黑盒：功能测试，保证每个功能正常的使用。 白盒：结构测试（单元测试），尽可能覆盖每个逻辑，每条分支。 类型 验证是否实现了功能（验收测试） 验证是否正确实现了功能（单元测试） 对产品可用性做测试，如响应时间、性能、安全等（非功能性测试） 覆盖范围 函数块的功能测试，不会启动服务（单元测试） 绕开用户界面，直接对服务调用测试（服务测试/集成测试） 打开用户界面进行测试（端对端测试） 不用过度纠结什么TDD、敏捷、极限编程之类的，可以先了解它们的思想，到了合适的时候，你会知道你需要的是什么。 为什么需要测试 为了客户！为了软件质量！（你懂的） 作为开发者，可能更多的面对是单元测试，其他的测试基本都是由QA负责的。也许我们是为了KPI而奋斗，但也是为了软件交付之后，不用提心吊胆的想着它什么时候会出问题。 在编写单元测试的过程中，能提前发现很多错误，看着日渐提高的测试覆盖率，就会有一种胜券在握的感觉。 当然它可能会额外占用你的一些时间，但从长久来看，这仍是一个非常有价值的投资。 不要为了测试而测试，即为了过度的追求覆盖率，写一些无意义的测试。 代码示例 以下用python写一个简单的示例 import unittest def sum(a, b): return a + b class TestCount(unittest.TestCase): def test_sum(self): total = sum(1, 2) self.assertEqual(total, 3) 我们有一个求和的方法sum，输入两个数字，看它是不是给我们返回预期值3。 看起来很简单，一看就看明白的东西，写个测试是不是觉得非常多余。 但是以后代码逻辑越来越复杂的时候，有个偷偷改了你的sum函数 def sum(a, b): return a - b 结果你跑测试用例的时候，发现会抛出个异常 self = &lt;t.TestCount testMethod=test_sum&gt; def test_sum(self): total = sum(1, 2) &gt; self.assertEqual(total, 3) E AssertionError: -1 != 3 你仔细一看，是不是想骂人？这还是求和的函数？一下就能抓住差点让你背锅的罪魁祸首。 如果你说，干完这一票，以后就不归你负责了。那我只能劝你善良。 怎么学 学习从什么时候开始都不晚，但请不要相信培训机构给你灌的毒鸡汤。 作为开发者，给自己的应用程序写写测试用例，那基本非常简单，查查文档，勤快一点都能搞定。 这个话题更多的面向的是专业的测试人员。 当你决定要成为一名伟大的测试人员，请确定以下参数： 有强大的自学能力 退一步说，培训机构也管不了你一辈子 确定自己的成长路线，针对性的进行学习 如果你只是为了能快速找到一份工作，可以对照招聘需求进行技能拆解，朝着你的目标前进。 以下是我理解的测试 文档类：测试计划、测试用例、测试报告、缺陷跟踪 技能类：接口测试、性能测试 希望能对你有所帮助，如有其他问题也可以跟我交流。 ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://xwl.io/tag/python/"}],"title":"软件测试快速入门指南","feature":"","link":"https://xwl.io/post/e5-HJIifG/","stats":{"text":"4 min read","time":196000,"words":930,"minutes":4},"date":"2021-05-03 15:43:48","dateFormat":"2021-05-03"},{"content":"既然你都点进来了，那么你将面临一个问题，为什么要打造个人品牌呢？ 我们可能需要有一个很明确的目标，才能够坚持，并持之以恒。 当然对于我来说，可能就是一个知识积累的前端分享平台，它包含着我对于碎片知识的整合，用于构建自己的知识体系，完善自身庞大的知识帝国。 下面我来分享一下，技术人如何打造自己的个人品牌。 定位 决定往哪个领域发展，比如做技术博客，或者更细化一点，深耕一个领域，运维工程、Java开发等。 这个定位可以从你的工作、兴趣爱好、奋斗目标等来挖掘，我就是个几乎没有爱好的技术宅，所以我不假思索的选择了工作。 定位好之后，你就可以选择平台，微信公众号、博客园、CSDN、自建网站等 值得注意的是，如果你也是个技术领域的人才，但请不要花费太多时间在折腾网站上，不要忘记创作的初衷。 专业 什么才能体现你的专业呢？当然是在你定位的领域中深耕。 我会把运维领域需要的技术，进行知识的体系化，比如系统、网络、监控、标准化建设等，可以用思维导图来构建你的知识图谱，细化这个领域所需要的知识、技能，然后围绕着这些节点做分享。 目标很简单，就是别人在这个领域遇到问题的时候，你可以看去某某做的分享，他的博客之类。 给大家分享一下，我在这个过程中踩过的坑，或者可能需要注意的几个问题。 内容要很牛逼？ 分享的内容不一定需要非常的牛逼，而是你分享的内容能帮助别人解决特定的问题，这就是有效的。 坚持 专业的人都有一个特质，那就是坚持在一个领域深耕。 开始一件事非常容易，但坚持很难，持续分享，持续输出，更是难上加难。 这个才是最最重要的，没有坚持，一切皆是虚妄。 独立思考 独立思考很重要，输出知识的同时，最好也携带着自己的观点。 此间最忌讳无脑复制，不加验证，说不定一个错误的文章也被复制的千百遍，会让大家怀疑你的水平。 文字功底 这个可能是需要技术人提高的地方，整篇文章全是代码，没有上下文，记流水账之类的，诸如此类，都会显得很low。 对此，可以了解一下结构化写作相关的内容。 曝光 酒香也怕巷子深。 当然这个观点可能也有些人不太认可，但我觉得还是有一定的道理的，除非你的酒香的出奇。 假如你是做个人网站，单纯的靠搜索引擎，用户检索到你文章的可能性很小了；哪怕你在平台发布，那么平台为什么给你推广资源呢？ 比如我作为一个技术人，我最常用的三个曝光方法： Github，在上面分享你的代码、作品，是最重要的背书之一。 写书，当你在某个领域深耕多年，你可以整理你积累的海量知识，提取出其中精华，当然电子书也是可以的。 活跃在各种技术论坛、博客，帮用户解决问题。 目标只有一个，就是宣传自己，让别人了解你，知道你的价值。 ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://xwl.io/tag/personal-growth/"}],"title":"关于程序员打造个人品牌","feature":"","link":"https://xwl.io/post/aD6fQ54QO/","stats":{"text":"4 min read","time":190000,"words":950,"minutes":4},"date":"2021-05-03 00:05:10","dateFormat":"2021-05-03"},{"content":"基本介绍 首先展示一张简单的架构图，会发现所有的流程几乎都是是通过api server通信的。 在开始之前先区分一些概念 • Pod：拥有一个Pod IP，是一个或一组容器组成。 • Service：为Pod实现负载均衡 • Endpoints：Endpoints表示了一个Service对应的所有Pod副本的访问地址，它负责监听Service和对应的Pod副本的变化。 • Ingress：通过Service获取其同名的Endpoints对象，使用是Endpoints存储的IP地址。 至于它们的关系，照惯例还是上个图比较清晰一些。 创建Pod 我们先大概看一下pod创建的整个流程。 基本分为三个部分： 通过各种方式去调用api server的接口，然后它会按照一定的格式存入etcd Master节点上的 Scheduler 监听api server Scheduler：简单的说就是通过一定的算法，把这个Pod分配到某个Worker节点上 Worker节点上的 Kubelet 监听api server 创建容器（CRI） 创建网络（CNI） 创建存储（CSI） 分配IP地址 更新Pod状态 以上流程没有涉及到Worker上的另一个组件，也就是Kube-proxy。 删除Pod 流程比较简单，也是通过api server去同步配置存储到etcd，然后Kubelet收到通知后负责删除Pod。 但Kubelet的步骤却完全相反，分别是： 删除存储（CSI） 删除网络（CNI） 删除容器（CRI） 在删除Pod的时候，会同时删除endpoint，kubelet也会接收到信号。 由于事件是并行的，可能会产生没有即时同步的情况，也就是endpoint还没有完成同步的时候，Pod已经同步完成了，这个时候访问就会出现问题。 如下图所示，运气最好的时候，也就是在endpoint完全同步之后，Pod才被删除。 怎么样保证优雅的删除呢？通常有以下几种方法： 当Pod即将被删除时，会收到SIGTERM信号，应用程序可以捕获该信号并开始关闭。 默认情况下，Kubernetes 将发送 SIGTERM 信号并等待 30 秒，然后强制终止该进程。 使用preStop钩子，等待15秒 以下是一个最简单的示例 apiVersion: v1 kind: Pod metadata: name: my-pod spec: containers: - name: web image: nginx ports: - name: web containerPort: 80 lifecycle: preStop: exec: command: [&quot;sleep&quot;, &quot;15&quot;] 那么它的流程会变成这样 仔细的朋友可能注意到有个Gracefule shutdown环节，此部分用于处理应用程序的优雅关闭。 假如你启动的是Nginx服务，那么YAML配置将会变成这样 apiVersion: v1 kind: Pod metadata: name: my-pod spec: containers: - name: web image: nginx ports: - name: web containerPort: 80 lifecycle: preStop: exec: command: [&quot;sleep&quot;, &quot;15&quot;, &quot;&amp;&amp;&quot;, &quot;nginx&quot;, &quot;-s&quot;, &quot;stop&quot;] 更新Pod 如果您有三个副本，并且一旦提交新的 YAML 资源 Kubernetes，则： 用新的容器镜像创建一个 Pod。 销毁现有的 Pod。 等待 Pod 准备就绪。 并重复上述步骤，直到所有 Pod 都迁移到较新的版本。 Kubernetes 仅在新的 Pod 准备好接收流量（通过 Readiness 检查）之后才重复每个周期。 这里顺便介绍一下Pod需要关注的两个探针 liveness：存活检测，如果探测失败了将会杀死容器。 readiness：就绪检测，检测容器是否准备好提供服务。 具体配置就不在这里详细叙述了。 ","tags":[{"index":-1,"name":"kubernetes","slug":"kubernetes","used":true,"link":"https://xwl.io/tag/kubernetes/"}],"title":"Kubernetes容器的启动/删除流程","feature":"","link":"https://xwl.io/post/SGNGDyGh1/","stats":{"text":"4 min read","time":197000,"words":862,"minutes":4},"date":"2021-05-02 18:03:08","dateFormat":"2021-05-02"},{"content":"夜深了 才会有喷涌而来的灵感 难得的假期就不搬砖写代码了。 无聊的时候也会刷刷微博，看看人生百态，也不管什么假不假的。 放假的日子总是特别无聊，不想出门，不想学习，不想打游戏，似乎什么都不想做。 也罢，让自己安静一会。 时间过的很快，不知不觉也毕业好几年，也接收过很多特点的观点，分享一下我的见解吧 不要用战术的勤奋掩盖战略的懒惰 这句话是雷军当年说的，起初听的时候也没什么感觉，当你有的经历之后，却能异常深刻。 道理其实很简单，要多思考，不要盲目的努力，但人的惰性会阻碍我们思考，很多情况下，我们宁愿勤奋到死也不愿思考一次。 知道是一回事，实践又是另一回事，就像之前盛行过的一句话，知道了很多道理，却依然过不好这一生。 在这个知识大爆炸的时代，大多数情况都是看过，之后它就会呆在了你的收藏夹里（别问我怎么知道）。 知识获取的成本真的很低，更多的价值体现在于，如何去筛选优质的内容，应用知识来解决问题的思维。 我遇到过最典型的例子就是，在网上找一个技术知识，网上有无数篇同样内容的文章，仔细一下，文中有好多处错误，也一并复制过去了。 这有何用？ 话题有点跑偏了，最后分享一下解决思路：人生每步都对，最后满盘皆输？ 文凭没那么重要，实力最重要 虽然这句话有一定的道理，但我还是要下个结论，文凭真的很重要！ 文凭是门槛，是敲门砖，没有的话很多时候都没办法展现自己的“实力”。 除非你的实力能够达到行业的前20%以上，28定律几乎在任何时候都适用，你的能力真的能强到这种程度，那文凭的作用确实对你来说几乎毫无作用，但我们更多的只是普通人，文凭对绝大多数人来说真的很重要。 学习是一辈子的事，文凭是你的外在，实力则是你的内涵，缺一不可。 试想，如果你外表长的过于丑陋，还会有人想了解你内心的美好吗？ 钱是赚出来的不是省出来的 这句话是对的，也是错的，大多数人都高估了自己的赚钱能力。 我刚毕业的时候，也是对这句话深信不疑，你可以花钱投资自己，用于买书、学习等，提高自己，那没问题，工资就算不高，该有的花费也绝对不能省。 可怕的就是消费主义盛行的今天，你对这句话就需要谨慎对待。比如说，买个ipad当生产力工具、买个kindle每天长通勤的时候看书，这个时候你需要思考一个问题，你真的需要它们吗？ 我也曾落入过消费主义陷阱，买了很多看似有用，实则却无用的东西，说不后悔是假的，好在我及时的看透了它 你会说，要有一个挣大钱的心，不要局限于省钱来致富。 好似你花钱多了，就能开阔眼界，提高格局？ 总结一句话就是，这句话的应用场景，用来投资自己非常正确，但用来消费大可不必。 或许你可以学习一下理财，感受一下延迟满足的快乐。 ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://xwl.io/tag/personal-growth/"}],"title":"来自长假第一天的挣扎","feature":"","link":"https://xwl.io/post/tgfaCQjnt/","stats":{"text":"4 min read","time":192000,"words":957,"minutes":4},"date":"2021-05-02 00:05:44","dateFormat":"2021-05-02"},{"content":"简介 上下文切换 (context switch)指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换；其实际含义是任务切换, 或者CPU寄存器切换 原因 当前正在执行的任务完成，系统的CPU正常调度下一个任务。 当前正在执行的任务遇到I/O等阻塞操作，调度器挂起此任务，继续调度下一个任务。 多个任务并发抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续调度下一个任务。 用户的代码挂起当前任务，比如线程执行sleep方法，让出CPU。 硬件中断。 一次系统调用的过程，其实是发生了两次 CPU 上下文切换。（用户态-&gt;内核态-&gt;用户态/同进程内的 CPU 上下文切换） 调度策略 处理器给每个线程分配 CPU 时间片（Time Slice），线程在分配获得的时间片内执行任务，一般为几十毫秒。在这么短的时间内线程互相切换，我们根本感觉不到，所以看上去就好像是同时进行的一样。 就是说，假如同时运行100个线程，CPU为了公平调度，会给每个线程分配时间片，当时间片耗尽之后会立即调度下一个线程（上下文切换） 线程与进程 概念 当进程只有一个线程时，可以认为进程就等于线程 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。 线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的 上下文切换 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据 解释 就单核系统而言，单位时间cpu能做的事情是固定的，这个上限并不因为使用多线程切换得到提高。 多线程出现的意义，就是为了解决IO和CPU之间速度差的冲突，在IO处理等待的时间，CPU可以去处理其他计算任务。 如果是每个线程一直就是在繁忙的计算，那么多个线程事实上也得不到任何好处，反而因为上下文的切换，要消耗比顺序执行更多的时间。 特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是导致平均负载升高的一个重要因素。 优化 无锁并发编程 控制进程/线程数量 协程，单进程单线程，内部任务切换 状态监测 pidstat -w -u 5 cswch ：表示每秒自愿上下文切换的次数 nvcswch：表示每秒非自愿上下文切换的次数 模拟场景工具 stress ：模拟进程、IO sysbench：模拟线程数 在OpenResty的场景举例 推荐配置是worker与CPU保持一致，这里是故意而为之。 由于worker的设计是单进程单线程的，这里我们的例子将模拟使用1个CPU使用2个worker进程 正常的上下文切换 ngx.say(&quot;hello&quot;) 这句话的意思是输出响应体，如果同时有两个用户进来，worker A和B会争抢CPU资源，假设A抢到了资源，那么B将被挂起，等待A执行完毕之后，CPU将会正常调度下一个任务。 主动的上下文切换 ngx.sleep(0) 以上操作是用来实现主动让出CPU，使用场景是在CPU密集型的程序段，长时间占用CPU，比如以下代码段 for i=10000000000000,1,-1 do print(i) end IO阻塞 os.getenv(&quot;SE_UPSTREAMS&quot;) 假设在access阶段，每个用户访问它都会从系统环境变量中取值，它就会造成阻塞，需要等待它完成之后CPU才会释放。这个过程经历的两次上下文切换（用户态-&gt;内核态-&gt;系统态）。可想而知，在高并发环境下，它将会造成阻塞，且会有大量的上下文切换。 ","tags":[{"index":-1,"name":"linux","slug":"linux","used":true,"link":"https://xwl.io/tag/linux/"}],"title":"操作系统的上下文切换","feature":"","link":"https://xwl.io/post/RlIk8BA71/","stats":{"text":"5 min read","time":251000,"words":1192,"minutes":5},"date":"2021-04-25 23:49:14","dateFormat":"2021-04-25"},{"content":"本文学习路径抄录了该项目大量文字 kube-ladder，相关知识会慢慢补齐。 入门篇 Kubernetes 的背景和优势 Kubernetes 环境的安装部署 Kubernetes 常用资源的使用方法 包括不限于Node、Pod、Service、Deployment、Namespace、ConfigMap、Secret。 原理篇 目标是了解Kubernetes的架构的核心组成部分，及其工作原理，容器从启动到结束整个生命周期的过程。 Kubernetes 的基础架构 Kubernetes 容器调度的基本流程 运维人员基本做到这一步就可以了，下面的内容将会涉及到开发。 集成篇 本节的目标是使用apiserver相关的接口，用于外部的服务集成。 ","tags":[{"index":-1,"name":"kubernetes","slug":"kubernetes","used":true,"link":"https://xwl.io/tag/kubernetes/"}],"title":"Kubernetes学习路径 & 教程","feature":"","link":"https://xwl.io/post/WpUHlquQY/","stats":{"text":"1 min read","time":38000,"words":178,"minutes":1},"date":"2021-04-24 00:31:44","dateFormat":"2021-04-24"},{"content":"基础组件 上图是kubernetes的基本组成部分，以下将简单描述一下其组件及其功能。 Master API Server：管理集群资源的唯一入口 Controller-Manager：一个资源对应一个控制器 Node Controller Deployment Controller Namespace Controller ... Scheduler：节点调度，选择Worker节点部署 Filter：选择符合Pod Spce描述的Node Score：打分和排序 Reserve：缓存数据，表示这个Pod已经分配到这个Node上 etcd：用于存储集群相关的数据 Worker kube-proxy：提供网络代理、负载均衡 实现的Proxy Mode支持iptables、ipvs Virtual IPs and service proxies 扩展阅读：性能提升40%: 腾讯 TKE 用 eBPF 绕过 conntrack 优化 K8s Service kubelet：管理本机的容器 基于 PodSpec 来工作的，每个 PodSpec 是一个描述 Pod 的 YAML 或 JSON 对象。 身份验证 每一次的访问请求都需要进行合法性的检验，其中包括身份验证、操作权限验证以及操作规范验证等，需要通过一系列验证通过之后才能访问。 工作流程 认证：验证账号的有效性 鉴权：拥有哪些访问权限 准入控制：自定义插件，API请求拦截器，它可以更改请求对象，甚至完全拒绝请求。 认证 拥有三种认证方式，分别是： Http Basic Authentication 基于证书认证（CA） 基于token认证 鉴权 基于RBAC，也就是角色访问控制。通俗的说，就是将权限赋予给角色，然后将角色绑定要用户主体上。 主体 user group 角色 role：特定命名空间访问权限 ClusterRole：所有命名空间访问角色 角色绑定 RoleBinding：角色绑定到主体 ClusterRoleBinding：集群角色绑定到主体 准入控制 我从网上扒了一个例子，供参考 去年曝光的 runC 漏洞（CVE-2019-5736），它被利用的原因之一就是容器内进程都是以 root 权限运行的。下面我们以这个问题为例，一起利用准入控制器 webhook 建立自定义安全策略。 为了解决上述问题，工程师可以使用自定义的变更准入控制器 Webhook 使默认设置变得更安全：除非明确要求，否则 webhook 将强制要求 Pod 以非 root 身份运行（示例中为分配 ID 1234）。 请注意，这个设置不会影响到集群中的工作负载，包括那些明确需要 root 权限的工作负载。 完整代码请见以下 admission-controller-webhook-demo Pod 启动流程 最后给大家分享一下容器的完整创建流程，对此有一个大概的认知。 ","tags":[{"index":-1,"name":"kubernetes","slug":"kubernetes","used":true,"link":"https://xwl.io/tag/kubernetes/"}],"title":"kubernetes基础架构","feature":"","link":"https://xwl.io/post/hhkktAeFo/","stats":{"text":"3 min read","time":146000,"words":668,"minutes":3},"date":"2021-04-22 21:46:29","dateFormat":"2021-04-22"},{"content":" 所有源码分析基于haproxy version 1.6.14 直接进入正题 核心代码如下task.c void process_runnable_tasks() { struct task *t; unsigned int max_processed; tasks_run_queue_cur = tasks_run_queue; nb_tasks_cur = nb_tasks; max_processed = tasks_run_queue; if (!tasks_run_queue) return; if (max_processed &gt; 200) max_processed = 200; if (likely(niced_tasks)) max_processed = (max_processed + 3) / 4; while (max_processed--) { if (unlikely(!rq_next)) { rq_next = eb32_lookup_ge(&amp;rqueue, rqueue_ticks - TIMER_LOOK_BACK); if (!rq_next) { rq_next = eb32_first(&amp;rqueue); if (!rq_next) break; } } t = eb32_entry(rq_next, struct task, rq); rq_next = eb32_next(rq_next); __task_unlink_rq(t); t-&gt;state |= TASK_RUNNING; t-&gt;calls++; if (likely(t-&gt;process == process_stream)) t = process_stream(t); else t = t-&gt;process(t); if (likely(t != NULL)) { t-&gt;state &amp;= ~TASK_RUNNING; if (t-&gt;expire) task_queue(t); } } } 简要说明 首先max_processed限制了每次最大只能处理200个任务 if (unlikely(!rq_next)) { rq_next = eb32_lookup_ge(&amp;rqueue, rqueue_ticks - TIMER_LOOK_BACK); if (!rq_next) { /* we might have reached the end of the tree, typically because * &lt;rqueue_ticks&gt; is in the first half and we're first scanning * the last half. Let's loop back to the beginning of the tree now. */ rq_next = eb32_first(&amp;rqueue); if (!rq_next) break; } } 如果下一个处理的任务为空，那么将回到队列的最前方。 t = eb32_entry(rq_next, struct task, rq); rq_next = eb32_next(rq_next); __task_unlink_rq(t); 我们获取到下一个任务之后，清除任务的队列信息，也就是删除当前的树节点 if (likely(t-&gt;process == process_stream)) t = process_stream(t); else t = t-&gt;process(t); if (likely(t != NULL)) { t-&gt;state &amp;= ~TASK_RUNNING; if (t-&gt;expire) task_queue(t); } 判断如果是处理请求的话，使用process_stream，还有其他多种情况，比如： process_check server_warmup process_email_alert dns_process_resolve session_expire_embryonic 函数分析 process_stream 这个函数只怕是有几千行哦，又长又臭：） 这个是haproxy处理任务的核心函数，代码内有一段注释说明。 Processes the client, server, request and response jobs of a stream task, then puts it back to the wait queue in a clean state 然后进行一些初始化工作 struct channel *req, *res; struct stream_interface *si_f, *si_b; req = &amp;s-&gt;req; res = &amp;s-&gt;res; si_f = &amp;s-&gt;si[0]; si_b = &amp;s-&gt;si[1]; si_f生产者，对应的是frontend端的句柄；而si_b为消费者，对应的backend端的句柄。 if (unlikely(s-&gt;pending_events &amp; TASK_WOKEN_TIMER)) { ... goto update_exp_and_leave } 此条件判断是否有超时事件，TASK_WOKEN_TIMER在任务超时的时候会被唤醒，然后开始检查si_f、si_b、req channel和res channel，随之将连接关闭。 然后进入update_exp_and_leave函数，此函数会将初始化过期时间，是其内部实现的一个ticks。释放buffer之后，使用stream_res_wakeup函数将其重新加入队列。 if (si_b-&gt;state == SI_ST_CON) { if (unlikely(!sess_update_st_con_tcp(s))) sess_update_st_cer(s); else if (si_b-&gt;state == SI_ST_EST) sess_establish(s); } 如果是状态为SI_ST_CON（发起连接请求），则进入此流程。检查连接是否是正常，sess_update_st_con_tcp检查连接，如果之前的连接建立失败了，使用sess_update_st_cer处理善后事宜，清空session等操作，如果需要重试的话，则使用process_srv_queue重新进入proxy queue。 如果状态是SI_ST_EST，说明连接建立成功，使用sess_establish初始化一些参数。 resync_stream_interface 作为子分支存在，主要用于检测连接可用性。 if (unlikely(si_f-&gt;state == SI_ST_DIS)) si_f-&gt;state = SI_ST_CLO; if (unlikely(si_b-&gt;state == SI_ST_DIS)) { si_b-&gt;state = SI_ST_CLO; srv = objt_server(s-&gt;target); if (srv) { if (s-&gt;flags &amp; SF_CURR_SESS) { s-&gt;flags &amp;= ~SF_CURR_SESS; srv-&gt;cur_sess--; } sess_change_server(s, NULL); if (may_dequeue_tasks(srv, s-&gt;be)) process_srv_queue(srv); } } may_dequeue_tasks 用于判断是否有必要开始下个连接 s-&gt;nbpend 等待处理的连接数 srv_is_usable 是否有可用的服务器 maxconn 最大连接数等 process_srv_queue 检测proxy queue的是否有正在等待处理的连接，并将它们全部唤醒。 resync_request 用于分析请求，主要函数 tcp_inspect_request http_wait_for_request http_wait_for_request_body http_process_req_common process_switching_rules tcp_inspect_request http_process_req_common process_server_rules http_process_request process_sticking_rules http_request_forward_body resync_response tcp_inspect_response http_wait_for_response process_store_rules http_process_res_common http_response_forward_body ","tags":[{"index":-1,"name":"haproxy","slug":"haproxy","used":true,"link":"https://xwl.io/tag/haproxy/"}],"title":"haproxy源码阅读（二）处理任务流程","feature":"","link":"https://xwl.io/post/TZUaQzhYM/","stats":{"text":"4 min read","time":239000,"words":852,"minutes":4},"date":"2021-04-16 23:45:38","dateFormat":"2021-04-16"},{"content":" 所有源码分析基于haproxy version 1.6.14 首先分析核心代码haproxy.c /* Runs the polling loop */ void run_poll_loop() { int next; tv_update_date(0,1); while (1) { /* Process a few tasks */ process_runnable_tasks(); /* check if we caught some signals and process them */ signal_process_queue(); /* Check if we can expire some tasks */ next = wake_expired_tasks(); /* stop when there's nothing left to do */ if (jobs == 0) break; /* expire immediately if events are pending */ if (fd_cache_num || tasks_run_queue || signal_queue_len || applets_active_queue) next = now_ms; /* The poller will ensure it returns around &lt;next&gt; */ cur_poller.poll(&amp;cur_poller, next); fd_process_cached_events(); applet_run_active(); } } 简要说明 process_runnable_tasks 处理可运行的任务 signal_process_queue 处理信号队列，如果捕获了信号则需要处理 wake_expired_tasks 处理超时任务 cur_poller.poll 更新fd事件到缓存 fd_process_cached_events 处理fd事件 函数分析 整体描述下函数的作用 process_runnable_tasks 取出队列中的任务，调用process_stream函数处理，返回之后重新将task放入等待队列 主要任务 根据预设的规则设置一个backend process_switching_rules -&gt; stream_set_backend 根据相应的调度算法，选择后端服务器，并添加到队列中 sess_prepare_conn_req -&gt; srv_redispatch_connect -&gt; assign_server_and_queue -&gt; assign_server -&gt; chash_get_next_server 后端服务器请求已满，添加到proxy队列 pendconn_add signal_process_queue 自身实现的信号处理机制，接收到信号之后输出到队列，然后在处理信号队列，保证所有请求处理完之后再关闭 wake_expired_tasks 唤醒超时任务，队列分为run queue／wait queue，该函数就是检查wait queue任务，并将其输出到run queue中，以便后续处理。 cur_poller.poll 获取所有活动的fd，并将其更新到cache中 主要函数 _do_poll epoll_wait fd_may_recv fd_may_send fd_update_cache fd_process_cached_events 处理fd事件，建立连接、数据收发等 主要函数 conn_fd_handler si_conn_recv_cb raw_sock_to_pipe/ssl_sock_to_buf raw_sock_to_buf si_conn_send_cb ","tags":[{"index":-1,"name":"haproxy","slug":"haproxy","used":true,"link":"https://xwl.io/tag/haproxy/"}],"title":"haproxy源码阅读（一）主循环流程","feature":"","link":"https://xwl.io/post/s5EVafZW4/","stats":{"text":"2 min read","time":105000,"words":408,"minutes":2},"date":"2021-04-15 23:39:58","dateFormat":"2021-04-15"},{"content":"基础环境配置 mac环境下，自带的是clang，在编辑haproxy的时候会出现一系列的warning，所以先安装下gcc，haproxy官方测试通过的只有4.x版本 brew install gcc@4.9 然后修改haproxy的Makefile，120行。 CC = /usr/local/Cellar/gcc\\@4.9/4.9.4_1/bin/gcc-4.9 编译安装 make TARGET=osx make install PREFIX=/opt/haproxy vscode 配置 tasks.json { &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ { &quot;label&quot;: &quot;haproxy&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;command&quot;: &quot;sudo make TARGET=osx &amp;&amp; sudo make install PREFIX=/opt/haproxy &amp;&amp; sudo make clean&quot;, &quot;problemMatcher&quot;: [ &quot;$gcc&quot; ] } ] } 此时运行任务的时候就自动执行tasks.json的任务，进行编译，完成之后就能顺利调试。 launch.json { &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;(gdb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;/opt/haproxy/sbin/haproxy&quot;, &quot;args&quot;: [&quot;-f&quot;, &quot;/opt/haproxy/etc/haproxy.cfg&quot;], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;${workspaceFolder}&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;lldb&quot; } ] } 这个配置是用于调试环境下的，执行二进制程序环境的命令，以及使用的调试工具gdb/lldb。 ","tags":[{"index":-1,"name":"haproxy","slug":"haproxy","used":true,"link":"https://xwl.io/tag/haproxy/"}],"title":"使用vscode调试haproxy","feature":"","link":"https://xwl.io/post/tS0UUUJy6/","stats":{"text":"2 min read","time":87000,"words":290,"minutes":2},"date":"2021-04-15 23:29:08","dateFormat":"2021-04-15"},{"content":" 孙圈圈，移动学习品牌“圈外同学” 创始人兼CEO，领英洞察、36Kr专栏作家，毕业于南京大学经济学系，曾担任美世咨询（全球最大的人力资源管理咨询公司）总监，为多家国内外知名企业服务，设计组织架构和人才发展体系，著有职场类畅销书《请停止无效努力:如何用正确的方法快速进阶》。 一、 看人很准的我，栽在实习生手上 我曾经是一名管理咨询顾问，从事咨询工作8年多，当时我主要的工作职责是帮公司制定他们的人才发展战略，同时研究什么样特质的人适合做什么样的岗位。 所以我的工作中有一部分是看人。 一些大公司在选拔高管继任者的时候，会找到我们，我会花几个小时跟候选人相处，评估他们各方面的能力，看是否符合岗位要求。 这些企业高管的候选人，往往是中年男性，他们成熟、世故、善于伪装，“宁愿相信世界上有鬼，也别相信中年男人那张嘴”。 所以在这种训练下，我一直认为，自己看人很准，直到有一次，“栽”到了实习生手上。 那时候，我有两个实习生，其中一个男生，聪明、理性、在复旦念书，而另一个女生，学校一般、面试表现一般。各位，如果你们是我，你会看好哪一个呢？我跟大多数人一样，看好前面一个，也着力培养。 几个月之后，我让他们同时帮我写一份项目建议书，男生做得不错，分析详细、逻辑严密。 但是给我惊喜的却是这个女生，报告非常有洞见，她甚至利用社交网络去找了行业内部人士做了访谈。为什么几个月会发生反转呢？ 我百思不得其解，跟一个前辈聊起这个问题，她问我两个实习生的工作态度、我在他们身上花的时间、他们做的事情有无差异等等，最后她问到：两个小朋友的职业目标是什么？ 那一刻我突然恍然大悟，我想起自己曾经跟他们聊过“野心”这个话题。 男生说，他的野心是成为跨国公司CEO、做一个出色的职业经理人，所以他再晚也会做完我分配的工作。 但是都会按照我给的步骤去做，不会过于激进地创新，因为他不敢犯错。 而女生呢，会问我“如果我5年后要创立自己的公司，现在做咨询合适吗？”可我甚至还没有决定是否要留下她呢！ 她常常跟我要求一些能力以外的事情去做，还会尝试一些她认为可行的方法，有时候做成，也有时候搞砸，虽然给人不稳定的感觉，但这么一来，她的确成长却更快了。 从那以后，我在选人用人的时候，我会额外关注一个人的野心，也就是他做事的动力。 二、 动力不是驱动我们享受的，而是驱动我们付出的 我有必要解释一下，这里的动力是什么含义。可能很多人说：动力，就是自己喜欢或者想要的东西。 那么在座各位，你喜欢什么呢？ 我曾经问过很多人这个问题，得到的回答基本是：睡觉睡到自然醒，数钱数到手抽筋，工作地点离家近…… Ok，这些不是动力，也不是野心，那是什么呢？ 这些是人性本能。 那什么是动力呢？人类历史上1953年第一次登上珠峰，但在1924年，就有人几乎登上过，这个人叫乔治马洛里。 剑桥大学毕业，凯恩斯的同学加好友，有一个非常恩爱的妻子，最重要的是，颜值超高！简直是人生赢家！我们都想成为他这样的人，不是吗？ 但是他却多次冒着生命危险登珠峰，那可是在100年前，人类没有去过珠峰，所以没有地图，那时候没有羽绒服，更不用提高原反应。 实际上，马洛里在第二次尝试的时候，就因为雪崩，眼睁睁看着7个队友丧生，但他还是去了第三次。 然后在离山顶只有几百米的地方，他永远留在了那里，直到几十年后，人们发现了他的尸体。 记者曾经问他为什么，他说“Because it’s there”，就是那句著名的“因为，山就在那里”。 所谓本能，就是明知道一些事是对的，但是自己做不到；而所谓动力，就是我们能够反本能地去做到那些事情。 怕冷、怕死、怕累，是出于本能；而克服这些“怕”去爬珠峰，是出于动力。所以，动力不是让我们享受的，恰恰相反，是让我们甘愿付出的。 三、 成功者的共性是动力 这种动力，到底有多重要呢？ 我曾经跟之前的同事一起，给过去服务过的企业高管和个人客户做了个数据分析，分析对象都是各大企业的成功领导者。 在这些人当中，各个跟领导力相关的能力项，几乎都可以找到反面的例子，比如有人战略思维欠缺，有人团队管理方面不够成熟，但也能成为成功领导者。 可是，几乎没有人缺乏passion for success（也就是追求成功的热情）这一项。 为什么动力会如此重要呢？它在我们的发展过程中，起到什么样的作用呢？ 相信大家都听说过冰山模型，是美国著名心理学家麦克利兰提出来的，它全面地描述了一个人的个体素质要素。 一条海平面把冰山分成了上下两部分。 海平面上面的部分，是知识、技能和能力，解决了一个人“能不能”做某件事情；而天赋特性包括价值观、性格特质等等，解决了一个人“愿不愿”做某件事情。 这三类要素是自下而上逐渐影响的，底层要素决定了上层，比如我们有动力学习，然后才有学习能力的提升，然后有了学习能力，也能学会更多知识。 根据研究，冰山底层的要素中，光个性特质就能够解释员工绩效差异的35%，而冰山底层的因素加起来差不多决定了一个人的70%。 并且越往底层的要素越难被我们发现，同时也越难被改变，比如个性特质，基本在成年之后就达到稳定状态，除非遭遇重大的人生变故。 所以，如果我们所做的事情，跟自己冰山下面的要素相违背，相当于我们用10分的努力，最多得到3分的结果；而另一个人，只要选对了事情，他可能就有7分了。 找到我们的动力，就是如此重要。 四、 大部分人的问题，是野心配不上才华 我们经常听说这样一句话，“要让才华配得上自己的野心”。 可现实情况其实恰恰相反，大部分人的野心，其实是配不上才华的。 因为，才华是能力，而野心是动力，我们花了很多时间提升自己，可却不知道为什么。 野心配不上才华会如何呢？我不知道各位有没有过这种时刻，反正大部分我都有过： 高考之前以分数为目标，被家长推着走，大学的时候跟同学混着走，4年毕业之后，突然面临一个问题“我要做什么工作”，于是彻底懵逼； 之后，找到一份不喜欢也不讨厌的工作，拿着一份不高也不低的工资，想要做点什么来改变，可不知道怎么改变； 然后，因为不知道要做什么，所以就到处找事做，办了健身卡、买了知识付费产品、打算考几个证，也的确学到了一些东西，但是都没坚持下去。 最后放弃了折腾，安慰自己说“可能人生就是这样吧”，对很多事情都没有了热情，除了刷抖音的时候。 这些问题背后，可能就是野心配不上才华。当然，我们大多数人如何概括这种现象呢？统称两个字：迷茫。 所以，如果我们去问一个年轻人：你迷茫吗？他多半会回答说：哎？你怎么知道？ 我当然知道，我们都迷茫嘛！ 所以，找到我们的野心，让它对得起我们的才华和努力！ 五、 这个方法，帮我找到了野心，改变了我的人生轨迹 如何才能找到呢？ 在我快30岁的时候，我成为了公司晋升最快的咨询顾问，而且如果继续待下去，可能会成为这里最年轻的合伙人。 但是，突然某一天，我不想继续了。 咨询公司或者说所有的大公司，都有一个非常清晰的职业发展通道，好像一把梯子，只要我上了梯子、往上爬一格，就会有人给我加油、有人跟我竞争、有人给我鲜花和掌声。 然后在那种氛围下，我竭尽全力一直往上爬，这些给了我很强的外部动力，让我待了8年。 可是，当我快爬到顶的时候，我看到了梯子最顶端的风景，我突然发现那不是我想要的。我不要在这儿玩儿了，可我要什么，我不知道。 于是，我开始自我治疗，当时跟很多人聊过，也找了很多资料，结合了很多方法，最终真的找到了一个方法，让我找到了自己的野心，也改变了我的人生轨迹。 后来我分享过给很多人，也改变了他们。今天，我分享给你们。 第一步，我停了下来，开始回忆自己过去8年，回忆自己特别兴奋或者厌恶的时刻。也就是，回忆过去这些年的巅峰体验。 为什么要回忆体验呢？很简单，我们的野心本身就来源于感觉。 比如，有人会说自己想赚一个亿，但钱并不是我们真正追求的东西，我们想要钱，是看中了背后的安全感，还是给了家人团聚的可能，还是证明自己成功呢？ 这背后的感觉，才是我们要找的。 第二步，我找了10个朋友，都是跟我非常亲近的朋友，问他们，我在做什么事情的时候最专注、最热情、两眼放光。 为什么要找朋友呢？因为我们看自己的很多行为往往觉得理所当然、习以为常，但是我们的朋友，他们会从旁观者的角度来告诉我们真相。 那些你觉得理所当然可别人觉得匪夷所思的事情，可能就是你的热情所在。 之后，我找了一个周末的下午，把自己关在房间里面，面前铺开一大叠纸，开始一个个写自己想要做到的事情，就这样写了100多个。 人生几十年，我第一次知道自己这么贪心，想要得这么多。在写的过程中，大概有五六个，都曾经让我心潮澎湃。 然后，看着这五六条，我再一个个删。 我告诉自己：删掉，就意味着我这辈子不可能实现它了。这个过程中，我从刚才的极度兴奋变成极度崩溃。 最后，一张纸上留下了最后一条。 那一条是：影响并帮助他人成长。 想象我不去服务企业，而是我能够把自己的专业知识和经验输出，直接帮助一个人，我就觉得无比兴奋！ 所以，做完最后这一步，找到野心之后，再去找到能够满足我们野心的事情就可以了。 于是，在那天下午之后的几个月，我就从咨询公司辞职了，开始创业，做一家帮助年轻人成长的公司（注：圈外同学）。 我很庆幸当时自己找到了我要的答案。 六、 我找到了野心，但我又输掉了它 但是，故事还没结束，后来我跟团队一起，做了一件更加刺激的事情。 我们差不多10几个人，把我们的野心放在一起，除了我上面说的那条之外，还有一些很吸引人的。 比如找到相伴一生的灵魂伴侣，比如能够流芳百世，比如永远美丽动人，等等。 然后我们做了一个野心拍卖会，每个人分到10个筹码，拍自己要的那个东西，这些筹码代表的是自己拥有的时间。 轮到我的拍品的时候，我先叫了1个筹码，然后有人叫到2，很明显，另一个人也想要这个，然后我叫3的时候，她没有叫4，而是直接10个筹码all in了。 我一下子蒙了，那是我最想要的东西，可它现在属于别人，我觉得自己快要哭出来了。 回顾刚才的拍卖过程，我明明知道那是我唯一想要的东西，我应该做的是10个筹码all in。 但是我觉得，有10个筹码嘛，说不定可以用几个拍到自己最想要的，然后剩一些来拍其他物品，毕竟那些也都很有吸引力啊！ 可当有人all in的时候，我输掉了。 这像极了我们的现实人生，很多时候，我们明明有自己内心想要的东西，但是当我们看到同学、朋友、亲戚手里的其他东西，又觉得“哎，好像也不错”。 非常羡慕他们，会想是不是也可以去试试，但最后，我们疲于奔命、什么也没有得到。 后来在我创业过程中，面临过很多次困境，也面临过很多诱惑，但每当这个时候，我就会想起拍卖会上，我失去野心的那种痛苦，然后我总能更容易地做出选择。 回到刚开始那两个实习生的故事，他们现在发展得都不错，男生在一家500强公司，而女生呢，现在在我们创业团队，而且她就是那个在拍卖会上跟我抢野心的人。 他们的野心和才华，都得到了最好的安排。 所以各位，我今天特别想分享这个观点：花一点时间，去找到自己的野心，然后聚焦，让它配得上我们的才华！ 我们都以为，那种所谓“野心”都离我们太远了，只有那些改变世界的人，比如乔布斯，才配得上谈野心。 但是，我们所有人都有属于自己的野心。 它并不是一个所有人都一致的东西，无论我们的野心是“改变世界”还是“家庭美满”，都是有价值的。 因为，它会让我们专注于自己的需求，让我们不再抱怨这样那样的不顺心，不再纠结这样那样的选择，不再羡慕别人有这样那样的东西。 我们的人生就像那座冰山，海平面上会有无数狂风暴雨，但只要找到了自己的野心，我们就能在海平面底下安然无恙。 所以，找到我们的野心，让它配得上我们的才华！ ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://xwl.io/tag/personal-growth/"}],"title":"别让我们的野心配不上才华｜圈圈@TEDx","feature":"","link":"https://xwl.io/post/sMLLztYXw/","stats":{"text":"14 min read","time":819000,"words":4063,"minutes":14},"date":"2021-04-13 21:51:05","dateFormat":"2021-04-13"},{"content":"简介 本站基于Gridea构建 也曾折腾过Wordpress、Ghost、Hexo、Hugo等博客，在来回迁移的痛苦中，却没有多少文章产出。 但请不要忘记初心❤️ 主流开源博客对比 Wordpress：什么都有，唯一的毛病都是慢。 Ghost：生态不错，但考虑到国内的网络环境和本地化程度，只适合做英文站。 Hexo：折腾型选手，缺点是文章过多编译时太慢。 Hugo：折腾型选手，编译效率上去了，但是写文章体验不是很好。 Gridea：有独立客户端，几乎没有生态，但用起来很方便，适合专注创作的朋友。 Gridea的同步问题 经常因为网络问题，出现同步失败的情况，是因为GitHub被墙的缘故，使用Ping工具去检查一下，然后找个延迟低的IP地址，替换一下Host即可。 本站构建使用的模块 以下是我现在使用的一些组件，给大家省点时间。 网站部署 GitHub Page + Cloudflare 客户端 Gridea 模版 Gridea-theme-Chic 评论系统 Valine + Leancloud 邮件订阅入口 Tinyletter ","tags":[{"index":-1,"name":"未归档","slug":"undefined","used":true,"link":"https://xwl.io/tag/undefined/"}],"title":"关于本站服务构建","feature":"","link":"https://xwl.io/post/5wRgq8uqf/","stats":{"text":"2 min read","time":61000,"words":286,"minutes":2},"date":"2021-04-01 01:20:49","dateFormat":"2021-04-01"}]}