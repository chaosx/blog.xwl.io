{"themeConfig":{"themeName":"Gridea-theme-Chic","postPageSize":10,"archivesPageSize":50,"siteName":"许大仙的博客","siteDescription":"一个运维人的成长历程","footerInfo":"","showFeatureImage":false,"domain":"https://blog.xwl.io","postUrlFormat":"SHORT_ID","tagUrlFormat":"SHORT_ID","dateFormat":"YYYY-MM-DD","feedFullText":false,"feedCount":20,"archivesPath":"archives","postPath":"post","tagPath":"tag"},"posts":[{"content":"都2021年了，个人博客都成为小众产品了，几乎都是开发者，十有八九还是个前端开发。 虽然GitHub时常被墙，但大部分人还是会选择GitHub Pages，以减少服务器的维护成本。 而作为个人博客站长，几乎都会不务正业的折腾各种功能模块，今天就来介绍SEO相关，关于网站收录的部分。 常用的搜索引擎一般分为以下三种： 百度 Google Bing 百度作为检索信息最多，且最乱的典型代表，你常常会在第一页找不到你想要的结果，但无奈它是我国最常用的搜索引擎。 常规的提交方法是去百度站长平台提交Sitemap，文件名一般为sitemap.xml，由于我目前使用的Gridea，没有生成Sitemap的方法，于是乎决定采用API的方式提交。 我们先准备好推送网站收录的脚本，以下是我写好的.push.py import re import json import requests domain = &quot;blog.xwl.io&quot; token = &quot;xxxxxxxxxx&quot; res = requests.get(&quot;https://%s/archives/&quot; % domain) tags = re.findall(r'href=&quot;([a-zA-z]+://[^\\s]*)&quot;', str(res.text)) urls = [] for t in tags: if t.endswith(&quot;css&quot;) or t.endswith(&quot;js&quot;):continue if not t.startswith(&quot;https://blog.xwl.io&quot;):continue urls.append(t) urls = &quot;\\n&quot;.join(urls) headers = {&quot;Content-Type&quot;: &quot;text/plain&quot;} resp = requests.post(&quot;http://data.zz.baidu.com/urls?site=https://%s&amp;token=%s&quot; &amp; (domain, token), headers=headers, data=urls) print(resp.text) 该脚本的功能是抓取网页上的所有链接，目标页面一般是首页，或者归档页，然后通过百度提供的API进行提交。 另外有两个值得注意的地方： 脚本中的token在百度站长平台内的普通收录里获取。 百度之前有个自动提交的JS，据我所知目前已经作废了，但接口还会正常返回。 然后我们进入到Github的博客项目中，选择Action，创建一个Workflow，会生成一个基础的模版，然后直接在steps路径下执行自己的脚本。 # This is a basic workflow to help you get started with Actions name: CI # Controls when the action will run. on: # Triggers the workflow on push or pull request events but only for the main branch push: branches: [ main ] pull_request: branches: [ main ] # Allows you to run this workflow manually from the Actions tab workflow_dispatch: # A workflow run is made up of one or more jobs that can run sequentially or in parallel jobs: # This workflow contains a single job called &quot;build&quot; build: # The type of runner that the job will run on runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it - uses: actions/checkout@v2 - name: update baidu uses: actions/setup-python@v2 with: python-version: '3.x' # Version range or exact version of a Python version to use, using SemVer's version range syntax architecture: 'x64' # optional x64 or x86. Defaults to x64 if not specified - run: pip install requests &amp;&amp; python .push.py 以上是我使用的完整的workflow配置，再添加上Google和Bing的部分，就大功告成了。 Google和Bing的Sitemap提交就非常的简单，直接通过一个GET请求即可。 在配置中的steps字段下继续增加即可。 - name: update google uses: wei/curl@master with: args: https://www.google.com/ping?sitemap=https://blog.xwl.io/atom.xml - name: update bing uses: wei/curl@master with: args: http://www.bing.com/webmaster/ping.aspx?sitemap=https://blog.xwl.io/atom.xml 把自己的小站弄的花里胡哨，除了知识的分享，也是希望更多的人能看到。 ","tags":[{"index":-1,"name":"github","slug":"github","used":true,"link":"https://blog.xwl.io/tag/github/"}],"title":"使用GitHub Action自动提交网站收录","feature":"","link":"https://blog.xwl.io/post/Qc51rd-j-/","stats":{"text":"4 min read","time":233000,"words":848,"minutes":4},"date":"2021-05-09 01:36:11","dateFormat":"2021-05-09"},{"content":"正好今晚处理了博客的SEO问题，配置了一下GitHub Action，就顺便回顾一下GitLab CI常用的策略吧。 背景 GitHub是一款非常优秀的产品，但企业还是更倾向于在内部自建仓库，所以在运维流程上，还是接触的GitLab稍多一些。 我刚来的时候公司运维环节比较薄弱，所以还是沿用之前的GitLab CI/CD流程，故学习了一阵，如果你们还没有完善的CI/CD流程，建议使用Jenkins。 简介 在GitLab CI上常用的动作 单元测试，跑完之后会有个测试覆盖率，部分企业会作为发布的硬性标准。 质量评估，可能会运行语法检测，或者集成一些第三方的代码质量管理平台，例如Sonar 打包容器，现在是云原生时代，建议使用，更多的应该关注业务本身，不应该过多的把时间花在重复配置环境上。 至于部署？ 实际生产上，从来都不会把部署的工作放到GitLab上做，不可控因素太多了。 除非就几个人的创业公司，为了省事，可以这样做。 言归正传，我们先看下完整的构建配置.gitlab-ci.yml stages: - unitest - qa - build variables: Name: example before_script: - echo &quot;run script&quot; job-unitest: stage: unitest job-qa: stage: qa job-build: stage: build 相比乱七八糟的教程，常用的就这么几种 stages，定义这个构建有几个流程，会按顺序执行下去，分别对应的job的stage字段 variables，定义环境变量，在之后的流程中可以引用它。 before_script，流程开始前，执行的准备工作，可以完成一些配置性的工作。 job-xxx，这个名字是可以随意定义的，只要stage字段匹配即可。 单元测试流程 也就是我们介绍的stage: unitest阶段，名称为job-unitest，可以随意定义。 拿Python举例，常用的方案会使用pytest进行单元测试工作，同时生成一个测试报告。 job-unitest: stage: unitest tags: - docker image: python:3 script: - pytest --junit-xml=report.xml 额外介绍一些tags，它的可选项一般为shell和docker作为它的Runner，建议使用后者，需要在编译Runner的时候集成docker。 shell模式的问题：会直接用Runner宿主机的shell命令，在多Runner环境下，要保证每台机器都要配置依赖环境，非常麻烦。 同时在以后的Runner升级工作中，可能会有未知的风险。 另外一种场景是，应用可能依赖数据库，那么配置就会变成这样。 job-unitest: stage: unitest tags: - docker image: python:3 services: - mysql:5.7 script: - pytest --junit-xml=report.xml 使用数据库的官方文档 GitLab CI MySQL 需要注意的是，MySQL的User字段可能为root，官方文档显示的是runner，注意对应版本。 友情提示：不会真有人忘记创建DB吧？ 容器打包流程 这个阶段没什么好说的，无外乎使用Dockerfile，进行build、push工作，直接给个范例。 job-bulid: stage: build tags: - docker services: - docker:dind image: docker:latest script: - docker build -t ${Name}:1.0 . - docker push 这里唯一要注意的，只有docker:dind这个服务，它是必须要存在的，否则会报错。 还记得之前我们定义过一个变量，这里就用上了。 push的命令我没有补全，自行查找文档。 睡了 狗命要紧。 ","tags":[{"index":-1,"name":"gitlab","slug":"gitlab","used":true,"link":"https://blog.xwl.io/tag/gitlab/"},{"index":-1,"name":"ci","slug":"ci","used":true,"link":"https://blog.xwl.io/tag/ci/"},{"index":-1,"name":"python","slug":"python","used":true,"link":"https://blog.xwl.io/tag/python/"}],"title":"关于GitLab CI常用策略","feature":"","link":"https://blog.xwl.io/post/okYjMtPcs/","stats":{"text":"4 min read","time":196000,"words":869,"minutes":4},"date":"2021-05-07 00:56:33","dateFormat":"2021-05-07"},{"content":"环境：Windows/Python 2 由于维护一些历史的.net项目，还运行在Windows平台上，在项目构建，甚至代码发布的过程中，需要解决一些技术债务问题。 Jinkens 我们采用的Windows下的Jenkins编译.net framework项目，在此过程中，该项目存在多个中文的文件名称，由于该项目有十几年历史，结构复杂不便改动，于是只能想法办兼容一下。 使用git获取差异文件列表 git diff --no-renames --name-only $commit_id_1 $commit_id_2 对比历史差异文件的时候，需提前执行以下命令，否则会造成中文乱码 git config --global core.quotepath false 然后我们在python脚本中处理文件名编码格式，由于是Windows平台，所以采用gbk编码。 filename.decode(&quot;utf-8&quot;).encode(&quot;gbk&quot;) Python 此外在python中使用zipfile模块进行压缩文件处理的时候，也要注意中文乱码问题 import zipfile zf = InMemoryZip('code.zip') p = InMemoryZip() for name in zf.get_namelist(): try: n = name.encode('cp437').decode('gbk') except: n = name.encode('utf-8').decode('utf-8') p.append(n, zf.open(name)) 在内存中操作ZIP压缩文件（附注代码） import os import io import zipfile class InMemoryZip(object): def __init__(self, buffer=None): # Create the in-memory file-like object self.in_memory_zip = io.BytesIO(buffer) if buffer: self.zf = zipfile.ZipFile(self.in_memory_zip, &quot;r&quot;) else: self.zf = zipfile.ZipFile(self.in_memory_zip, &quot;a&quot;, zipfile.ZIP_DEFLATED, False) def append(self, filename, file_contents): # Write the file to the in-memory zip # zf.writestr(filename_in_zip, file_contents) self.zf.writestr(filename, file_contents) # Mark the files as having been created on Windows so that # Unix permissions are not inferred as 0000 for zfile in self.zf.filelist: zfile.create_system = 0 return self def read_file(self, name): return self.zf.open(name).read() def extractall(self, directory): self.zf.extractall(directory) def get_namelist(self): return self.zf.namelist() def read(self): &quot;&quot;&quot;Returns a string with the contents of the in-memory zip.&quot;&quot;&quot; self.zf.close() self.in_memory_zip.seek(0) return self.in_memory_zip.read() ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://blog.xwl.io/tag/python/"}],"title":"Python 2的中文编码问题","feature":"","link":"https://blog.xwl.io/post/Fml9VHfUQ/","stats":{"text":"3 min read","time":130000,"words":449,"minutes":3},"date":"2021-05-05 00:27:06","dateFormat":"2021-05-05"},{"content":"测试的概念 以下只是为了让大家更快的熟悉整个测试体系，不用过度区分概念是否严谨。 总体可分为 黑盒：功能测试，保证每个功能正常的使用。 白盒：结构测试（单元测试），尽可能覆盖每个逻辑，每条分支。 类型 验证是否实现了功能（验收测试） 验证是否正确实现了功能（单元测试） 对产品可用性做测试，如响应时间、性能、安全等（非功能性测试） 覆盖范围 函数块的功能测试，不会启动服务（单元测试） 绕开用户界面，直接对服务调用测试（服务测试/集成测试） 打开用户界面进行测试（端对端测试） 不用过度纠结什么TDD、敏捷、极限编程之类的，可以先了解它们的思想，到了合适的时候，你会知道你需要的是什么。 为什么需要测试 为了客户！为了软件质量！（你懂的） 作为开发者，可能更多的面对是单元测试，其他的测试基本都是由QA负责的。也许我们是为了KPI而奋斗，但也是为了软件交付之后，不用提心吊胆的想着它什么时候会出问题。 在编写单元测试的过程中，能提前发现很多错误，看着日渐提高的测试覆盖率，就会有一种胜券在握的感觉。 当然它可能会额外占用你的一些时间，但从长久来看，这仍是一个非常有价值的投资。 不要为了测试而测试，即为了过度的追求覆盖率，写一些无意义的测试。 代码示例 以下用python写一个简单的示例 import unittest def sum(a, b): return a + b class TestCount(unittest.TestCase): def test_sum(self): total = sum(1, 2) self.assertEqual(total, 3) 我们有一个求和的方法sum，输入两个数字，看它是不是给我们返回预期值3。 看起来很简单，一看就看明白的东西，写个测试是不是觉得非常多余。 但是以后代码逻辑越来越复杂的时候，有个偷偷改了你的sum函数 def sum(a, b): return a - b 结果你跑测试用例的时候，发现会抛出个异常 self = &lt;t.TestCount testMethod=test_sum&gt; def test_sum(self): total = sum(1, 2) &gt; self.assertEqual(total, 3) E AssertionError: -1 != 3 你仔细一看，是不是想骂人？这还是求和的函数？一下就能抓住差点让你背锅的罪魁祸首。 如果你说，干完这一票，以后就不归你负责了。那我只能劝你善良。 怎么学 学习从什么时候开始都不晚，但请不要相信培训机构给你灌的毒鸡汤。 作为开发者，给自己的应用程序写写测试用例，那基本非常简单，查查文档，勤快一点都能搞定。 这个话题更多的面向的是专业的测试人员。 当你决定要成为一名伟大的测试人员，请确定以下参数： 有强大的自学能力 退一步说，培训机构也管不了你一辈子 确定自己的成长路线，针对性的进行学习 如果你只是为了能快速找到一份工作，可以对照招聘需求进行技能拆解，朝着你的目标前进。 以下是我理解的测试 文档类：测试计划、测试用例、测试报告、缺陷跟踪 技能类：接口测试、性能测试 希望能对你有所帮助，如有其他问题也可以跟我交流。 ","tags":[{"index":-1,"name":"python","slug":"python","used":true,"link":"https://blog.xwl.io/tag/python/"}],"title":"软件测试快速入门指南","feature":"","link":"https://blog.xwl.io/post/e5-HJIifG/","stats":{"text":"4 min read","time":196000,"words":930,"minutes":4},"date":"2021-05-03 15:43:48","dateFormat":"2021-05-03"},{"content":"既然你都点进来了，那么你将面临一个问题，为什么要打造个人品牌呢？ 我们可能需要有一个很明确的目标，才能够坚持，并持之以恒。 当然对于我来说，可能就是一个知识积累的前端分享平台，它包含着我对于碎片知识的整合，用于构建自己的知识体系，完善自身庞大的知识帝国。 下面我来分享一下，技术人如何打造自己的个人品牌。 定位 决定往哪个领域发展，比如做技术博客，或者更细化一点，深耕一个领域，运维工程、Java开发等。 这个定位可以从你的工作、兴趣爱好、奋斗目标等来挖掘，我就是个几乎没有爱好的技术宅，所以我不假思索的选择了工作。 定位好之后，你就可以选择平台，微信公众号、博客园、CSDN、自建网站等 值得注意的是，如果你也是个技术领域的人才，但请不要花费太多时间在折腾网站上，不要忘记创作的初衷。 专业 什么才能体现你的专业呢？当然是在你定位的领域中深耕。 我会把运维领域需要的技术，进行知识的体系化，比如系统、网络、监控、标准化建设等，可以用思维导图来构建你的知识图谱，细化这个领域所需要的知识、技能，然后围绕着这些节点做分享。 目标很简单，就是别人在这个领域遇到问题的时候，你可以看去某某做的分享，他的博客之类。 给大家分享一下，我在这个过程中踩过的坑，或者可能需要注意的几个问题。 内容要很牛逼？ 分享的内容不一定需要非常的牛逼，而是你分享的内容能帮助别人解决特定的问题，这就是有效的。 坚持 专业的人都有一个特质，那就是坚持在一个领域深耕。 开始一件事非常容易，但坚持很难，持续分享，持续输出，更是难上加难。 这个才是最最重要的，没有坚持，一切皆是虚妄。 独立思考 独立思考很重要，输出知识的同时，最好也携带着自己的观点。 此间最忌讳无脑复制，不加验证，说不定一个错误的文章也被复制的千百遍，会让大家怀疑你的水平。 文字功底 这个可能是需要技术人提高的地方，整篇文章全是代码，没有上下文，记流水账之类的，诸如此类，都会显得很low。 对此，可以了解一下结构化写作相关的内容。 曝光 酒香也怕巷子深。 当然这个观点可能也有些人不太认可，但我觉得还是有一定的道理的，除非你的酒香的出奇。 假如你是做个人网站，单纯的靠搜索引擎，用户检索到你文章的可能性很小了；哪怕你在平台发布，那么平台为什么给你推广资源呢？ 比如我作为一个技术人，我最常用的三个曝光方法： Github，在上面分享你的代码、作品，是最重要的背书之一。 写书，当你在某个领域深耕多年，你可以整理你积累的海量知识，提取出其中精华，当然电子书也是可以的。 活跃在各种技术论坛、博客，帮用户解决问题。 目标只有一个，就是宣传自己，让别人了解你，知道你的价值。 ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://blog.xwl.io/tag/personal-growth/"}],"title":"关于程序员打造个人品牌","feature":"","link":"https://blog.xwl.io/post/aD6fQ54QO/","stats":{"text":"4 min read","time":190000,"words":950,"minutes":4},"date":"2021-05-03 00:05:10","dateFormat":"2021-05-03"},{"content":"基本介绍 首先展示一张简单的架构图，会发现所有的流程几乎都是是通过api server通信的。 在开始之前先区分一些概念 • Pod：拥有一个Pod IP，是一个或一组容器组成。 • Service：为Pod实现负载均衡 • Endpoints：Endpoints表示了一个Service对应的所有Pod副本的访问地址，它负责监听Service和对应的Pod副本的变化。 • Ingress：通过Service获取其同名的Endpoints对象，使用是Endpoints存储的IP地址。 至于它们的关系，照惯例还是上个图比较清晰一些。 创建Pod 我们先大概看一下pod创建的整个流程。 基本分为三个部分： 通过各种方式去调用api server的接口，然后它会按照一定的格式存入etcd Master节点上的 Scheduler 监听api server Scheduler：简单的说就是通过一定的算法，把这个Pod分配到某个Worker节点上 Worker节点上的 Kubelet 监听api server 创建容器（CRI） 创建网络（CNI） 创建存储（CSI） 分配IP地址 更新Pod状态 以上流程没有涉及到Worker上的另一个组件，也就是Kube-proxy。 删除Pod 流程比较简单，也是通过api server去同步配置存储到etcd，然后Kubelet收到通知后负责删除Pod。 但Kubelet的步骤却完全相反，分别是： 删除存储（CSI） 删除网络（CNI） 删除容器（CRI） 在删除Pod的时候，会同时删除endpoint，kubelet也会接收到信号。 由于事件是并行的，可能会产生没有即时同步的情况，也就是endpoint还没有完成同步的时候，Pod已经同步完成了，这个时候访问就会出现问题。 如下图所示，运气最好的时候，也就是在endpoint完全同步之后，Pod才被删除。 怎么样保证优雅的删除呢？通常有以下几种方法： 当Pod即将被删除时，会收到SIGTERM信号，应用程序可以捕获该信号并开始关闭。 默认情况下，Kubernetes 将发送 SIGTERM 信号并等待 30 秒，然后强制终止该进程。 使用preStop钩子，等待15秒 以下是一个最简单的示例 apiVersion: v1 kind: Pod metadata: name: my-pod spec: containers: - name: web image: nginx ports: - name: web containerPort: 80 lifecycle: preStop: exec: command: [&quot;sleep&quot;, &quot;15&quot;] 那么它的流程会变成这样 仔细的朋友可能注意到有个Gracefule shutdown环节，此部分用于处理应用程序的优雅关闭。 假如你启动的是Nginx服务，那么YAML配置将会变成这样 apiVersion: v1 kind: Pod metadata: name: my-pod spec: containers: - name: web image: nginx ports: - name: web containerPort: 80 lifecycle: preStop: exec: command: [&quot;sleep&quot;, &quot;15&quot;, &quot;&amp;&amp;&quot;, &quot;nginx&quot;, &quot;-s&quot;, &quot;stop&quot;] 更新Pod 如果您有三个副本，并且一旦提交新的 YAML 资源 Kubernetes，则： 用新的容器镜像创建一个 Pod。 销毁现有的 Pod。 等待 Pod 准备就绪。 并重复上述步骤，直到所有 Pod 都迁移到较新的版本。 Kubernetes 仅在新的 Pod 准备好接收流量（通过 Readiness 检查）之后才重复每个周期。 这里顺便介绍一下Pod需要关注的两个探针 liveness：存活检测，如果探测失败了将会杀死容器。 readiness：就绪检测，检测容器是否准备好提供服务。 具体配置就不在这里详细叙述了。 ","tags":[{"index":-1,"name":"kubernetes","slug":"kubernetes","used":true,"link":"https://blog.xwl.io/tag/kubernetes/"}],"title":"Kubernetes容器的启动/删除流程","feature":"","link":"https://blog.xwl.io/post/SGNGDyGh1/","stats":{"text":"4 min read","time":197000,"words":862,"minutes":4},"date":"2021-05-02 18:03:08","dateFormat":"2021-05-02"},{"content":"夜深了 才会有喷涌而来的灵感 难得的假期就不搬砖写代码了。 无聊的时候也会刷刷微博，看看人生百态，也不管什么假不假的。 放假的日子总是特别无聊，不想出门，不想学习，不想打游戏，似乎什么都不想做。 也罢，让自己安静一会。 时间过的很快，不知不觉也毕业好几年，也接收过很多特点的观点，分享一下我的见解吧 不要用战术的勤奋掩盖战略的懒惰 这句话是雷军当年说的，起初听的时候也没什么感觉，当你有的经历之后，却能异常深刻。 道理其实很简单，要多思考，不要盲目的努力，但人的惰性会阻碍我们思考，很多情况下，我们宁愿勤奋到死也不愿思考一次。 知道是一回事，实践又是另一回事，就像之前盛行过的一句话，知道了很多道理，却依然过不好这一生。 在这个知识大爆炸的时代，大多数情况都是看过，之后它就会呆在了你的收藏夹里（别问我怎么知道）。 知识获取的成本真的很低，更多的价值体现在于，如何去筛选优质的内容，应用知识来解决问题的思维。 我遇到过最典型的例子就是，在网上找一个技术知识，网上有无数篇同样内容的文章，仔细一下，文中有好多处错误，也一并复制过去了。 这有何用？ 话题有点跑偏了，最后分享一下解决思路：人生每步都对，最后满盘皆输？ 文凭没那么重要，实力最重要 虽然这句话有一定的道理，但我还是要下个结论，文凭真的很重要！ 文凭是门槛，是敲门砖，没有的话很多时候都没办法展现自己的“实力”。 除非你的实力能够达到行业的前20%以上，28定律几乎在任何时候都适用，你的能力真的能强到这种程度，那文凭的作用确实对你来说几乎毫无作用，但我们更多的只是普通人，文凭对绝大多数人来说真的很重要。 学习是一辈子的事，文凭是你的外在，实力则是你的内涵，缺一不可。 试想，如果你外表长的过于丑陋，还会有人想了解你内心的美好吗？ 钱是赚出来的不是省出来的 这句话是对的，也是错的，大多数人都高估了自己的赚钱能力。 我刚毕业的时候，也是对这句话深信不疑，你可以花钱投资自己，用于买书、学习等，提高自己，那没问题，工资就算不高，该有的花费也绝对不能省。 可怕的就是消费主义盛行的今天，你对这句话就需要谨慎对待。比如说，买个ipad当生产力工具、买个kindle每天长通勤的时候看书，这个时候你需要思考一个问题，你真的需要它们吗？ 我也曾落入过消费主义陷阱，买了很多看似有用，实则却无用的东西，说不后悔是假的，好在我及时的看透了它 你会说，要有一个挣大钱的心，不要局限于省钱来致富。 好似你花钱多了，就能开阔眼界，提高格局？ 总结一句话就是，这句话的应用场景，用来投资自己非常正确，但用来消费大可不必。 或许你可以学习一下理财，感受一下延迟满足的快乐。 ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://blog.xwl.io/tag/personal-growth/"}],"title":"来自长假第一天的挣扎","feature":"","link":"https://blog.xwl.io/post/tgfaCQjnt/","stats":{"text":"4 min read","time":192000,"words":957,"minutes":4},"date":"2021-05-02 00:05:44","dateFormat":"2021-05-02"},{"content":"简介 上下文切换 (context switch)指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换；其实际含义是任务切换, 或者CPU寄存器切换 原因 当前正在执行的任务完成，系统的CPU正常调度下一个任务。 当前正在执行的任务遇到I/O等阻塞操作，调度器挂起此任务，继续调度下一个任务。 多个任务并发抢占锁资源，当前任务没有抢到锁资源，被调度器挂起，继续调度下一个任务。 用户的代码挂起当前任务，比如线程执行sleep方法，让出CPU。 硬件中断。 一次系统调用的过程，其实是发生了两次 CPU 上下文切换。（用户态-&gt;内核态-&gt;用户态/同进程内的 CPU 上下文切换） 调度策略 处理器给每个线程分配 CPU 时间片（Time Slice），线程在分配获得的时间片内执行任务，一般为几十毫秒。在这么短的时间内线程互相切换，我们根本感觉不到，所以看上去就好像是同时进行的一样。 就是说，假如同时运行100个线程，CPU为了公平调度，会给每个线程分配时间片，当时间片耗尽之后会立即调度下一个线程（上下文切换） 线程与进程 概念 当进程只有一个线程时，可以认为进程就等于线程 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。 线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的 上下文切换 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样。 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据 解释 就单核系统而言，单位时间cpu能做的事情是固定的，这个上限并不因为使用多线程切换得到提高。 多线程出现的意义，就是为了解决IO和CPU之间速度差的冲突，在IO处理等待的时间，CPU可以去处理其他计算任务。 如果是每个线程一直就是在繁忙的计算，那么多个线程事实上也得不到任何好处，反而因为上下文的切换，要消耗比顺序执行更多的时间。 特别是在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在寄存器、内核栈以及虚拟内存等资源的保存和恢复上，进而大大缩短了真正运行进程的时间。这也正是导致平均负载升高的一个重要因素。 优化 无锁并发编程 控制进程/线程数量 协程，单进程单线程，内部任务切换 状态监测 pidstat -w -u 5 cswch ：表示每秒自愿上下文切换的次数 nvcswch：表示每秒非自愿上下文切换的次数 模拟场景工具 stress ：模拟进程、IO sysbench：模拟线程数 在OpenResty的场景举例 推荐配置是worker与CPU保持一致，这里是故意而为之。 由于worker的设计是单进程单线程的，这里我们的例子将模拟使用1个CPU使用2个worker进程 正常的上下文切换 ngx.say(&quot;hello&quot;) 这句话的意思是输出响应体，如果同时有两个用户进来，worker A和B会争抢CPU资源，假设A抢到了资源，那么B将被挂起，等待A执行完毕之后，CPU将会正常调度下一个任务。 主动的上下文切换 ngx.sleep(0) 以上操作是用来实现主动让出CPU，使用场景是在CPU密集型的程序段，长时间占用CPU，比如以下代码段 for i=10000000000000,1,-1 do print(i) end IO阻塞 os.getenv(&quot;SE_UPSTREAMS&quot;) 假设在access阶段，每个用户访问它都会从系统环境变量中取值，它就会造成阻塞，需要等待它完成之后CPU才会释放。这个过程经历的两次上下文切换（用户态-&gt;内核态-&gt;系统态）。可想而知，在高并发环境下，它将会造成阻塞，且会有大量的上下文切换。 ","tags":[{"index":-1,"name":"linux","slug":"linux","used":true,"link":"https://blog.xwl.io/tag/linux/"}],"title":"操作系统的上下文切换","feature":"","link":"https://blog.xwl.io/post/RlIk8BA71/","stats":{"text":"5 min read","time":251000,"words":1192,"minutes":5},"date":"2021-04-25 23:49:14","dateFormat":"2021-04-25"},{"content":"本文学习路径抄录了该项目大量文字 kube-ladder，相关知识会慢慢补齐。 入门篇 Kubernetes 的背景和优势 Kubernetes 环境的安装部署 Kubernetes 常用资源的使用方法 包括不限于Node、Pod、Service、Deployment、Namespace、ConfigMap、Secret。 原理篇 目标是了解Kubernetes的架构的核心组成部分，及其工作原理，容器从启动到结束整个生命周期的过程。 Kubernetes 的基础架构 Kubernetes 容器调度的基本流程 运维人员基本做到这一步就可以了，下面的内容将会涉及到开发。 集成篇 本节的目标是使用apiserver相关的接口，用于外部的服务集成。 ","tags":[{"index":-1,"name":"kubernetes","slug":"kubernetes","used":true,"link":"https://blog.xwl.io/tag/kubernetes/"}],"title":"Kubernetes学习路径 & 教程","feature":"","link":"https://blog.xwl.io/post/WpUHlquQY/","stats":{"text":"1 min read","time":38000,"words":178,"minutes":1},"date":"2021-04-24 00:31:44","dateFormat":"2021-04-24"},{"content":"基础组件 上图是kubernetes的基本组成部分，以下将简单描述一下其组件及其功能。 Master API Server：管理集群资源的唯一入口 Controller-Manager：一个资源对应一个控制器 Node Controller Deployment Controller Namespace Controller ... Scheduler：节点调度，选择Worker节点部署 Filter：选择符合Pod Spce描述的Node Score：打分和排序 Reserve：缓存数据，表示这个Pod已经分配到这个Node上 etcd：用于存储集群相关的数据 Worker kube-proxy：提供网络代理、负载均衡 实现的Proxy Mode支持iptables、ipvs Virtual IPs and service proxies 扩展阅读：性能提升40%: 腾讯 TKE 用 eBPF 绕过 conntrack 优化 K8s Service kubelet：管理本机的容器 基于 PodSpec 来工作的，每个 PodSpec 是一个描述 Pod 的 YAML 或 JSON 对象。 身份验证 每一次的访问请求都需要进行合法性的检验，其中包括身份验证、操作权限验证以及操作规范验证等，需要通过一系列验证通过之后才能访问。 工作流程 认证：验证账号的有效性 鉴权：拥有哪些访问权限 准入控制：自定义插件，API请求拦截器，它可以更改请求对象，甚至完全拒绝请求。 认证 拥有三种认证方式，分别是： Http Basic Authentication 基于证书认证（CA） 基于token认证 鉴权 基于RBAC，也就是角色访问控制。通俗的说，就是将权限赋予给角色，然后将角色绑定要用户主体上。 主体 user group 角色 role：特定命名空间访问权限 ClusterRole：所有命名空间访问角色 角色绑定 RoleBinding：角色绑定到主体 ClusterRoleBinding：集群角色绑定到主体 准入控制 我从网上扒了一个例子，供参考 去年曝光的 runC 漏洞（CVE-2019-5736），它被利用的原因之一就是容器内进程都是以 root 权限运行的。下面我们以这个问题为例，一起利用准入控制器 webhook 建立自定义安全策略。 为了解决上述问题，工程师可以使用自定义的变更准入控制器 Webhook 使默认设置变得更安全：除非明确要求，否则 webhook 将强制要求 Pod 以非 root 身份运行（示例中为分配 ID 1234）。 请注意，这个设置不会影响到集群中的工作负载，包括那些明确需要 root 权限的工作负载。 完整代码请见以下 admission-controller-webhook-demo Pod 启动流程 最后给大家分享一下容器的完整创建流程，对此有一个大概的认知。 ","tags":[{"index":-1,"name":"kubernetes","slug":"kubernetes","used":true,"link":"https://blog.xwl.io/tag/kubernetes/"}],"title":"kubernetes基础架构","feature":"","link":"https://blog.xwl.io/post/hhkktAeFo/","stats":{"text":"3 min read","time":146000,"words":668,"minutes":3},"date":"2021-04-22 21:46:29","dateFormat":"2021-04-22"},{"content":" 所有源码分析基于haproxy version 1.6.14 直接进入正题 核心代码如下task.c void process_runnable_tasks() { struct task *t; unsigned int max_processed; tasks_run_queue_cur = tasks_run_queue; nb_tasks_cur = nb_tasks; max_processed = tasks_run_queue; if (!tasks_run_queue) return; if (max_processed &gt; 200) max_processed = 200; if (likely(niced_tasks)) max_processed = (max_processed + 3) / 4; while (max_processed--) { if (unlikely(!rq_next)) { rq_next = eb32_lookup_ge(&amp;rqueue, rqueue_ticks - TIMER_LOOK_BACK); if (!rq_next) { rq_next = eb32_first(&amp;rqueue); if (!rq_next) break; } } t = eb32_entry(rq_next, struct task, rq); rq_next = eb32_next(rq_next); __task_unlink_rq(t); t-&gt;state |= TASK_RUNNING; t-&gt;calls++; if (likely(t-&gt;process == process_stream)) t = process_stream(t); else t = t-&gt;process(t); if (likely(t != NULL)) { t-&gt;state &amp;= ~TASK_RUNNING; if (t-&gt;expire) task_queue(t); } } } 简要说明 首先max_processed限制了每次最大只能处理200个任务 if (unlikely(!rq_next)) { rq_next = eb32_lookup_ge(&amp;rqueue, rqueue_ticks - TIMER_LOOK_BACK); if (!rq_next) { /* we might have reached the end of the tree, typically because * &lt;rqueue_ticks&gt; is in the first half and we're first scanning * the last half. Let's loop back to the beginning of the tree now. */ rq_next = eb32_first(&amp;rqueue); if (!rq_next) break; } } 如果下一个处理的任务为空，那么将回到队列的最前方。 t = eb32_entry(rq_next, struct task, rq); rq_next = eb32_next(rq_next); __task_unlink_rq(t); 我们获取到下一个任务之后，清除任务的队列信息，也就是删除当前的树节点 if (likely(t-&gt;process == process_stream)) t = process_stream(t); else t = t-&gt;process(t); if (likely(t != NULL)) { t-&gt;state &amp;= ~TASK_RUNNING; if (t-&gt;expire) task_queue(t); } 判断如果是处理请求的话，使用process_stream，还有其他多种情况，比如： process_check server_warmup process_email_alert dns_process_resolve session_expire_embryonic 函数分析 process_stream 这个函数只怕是有几千行哦，又长又臭：） 这个是haproxy处理任务的核心函数，代码内有一段注释说明。 Processes the client, server, request and response jobs of a stream task, then puts it back to the wait queue in a clean state 然后进行一些初始化工作 struct channel *req, *res; struct stream_interface *si_f, *si_b; req = &amp;s-&gt;req; res = &amp;s-&gt;res; si_f = &amp;s-&gt;si[0]; si_b = &amp;s-&gt;si[1]; si_f生产者，对应的是frontend端的句柄；而si_b为消费者，对应的backend端的句柄。 if (unlikely(s-&gt;pending_events &amp; TASK_WOKEN_TIMER)) { ... goto update_exp_and_leave } 此条件判断是否有超时事件，TASK_WOKEN_TIMER在任务超时的时候会被唤醒，然后开始检查si_f、si_b、req channel和res channel，随之将连接关闭。 然后进入update_exp_and_leave函数，此函数会将初始化过期时间，是其内部实现的一个ticks。释放buffer之后，使用stream_res_wakeup函数将其重新加入队列。 if (si_b-&gt;state == SI_ST_CON) { if (unlikely(!sess_update_st_con_tcp(s))) sess_update_st_cer(s); else if (si_b-&gt;state == SI_ST_EST) sess_establish(s); } 如果是状态为SI_ST_CON（发起连接请求），则进入此流程。检查连接是否是正常，sess_update_st_con_tcp检查连接，如果之前的连接建立失败了，使用sess_update_st_cer处理善后事宜，清空session等操作，如果需要重试的话，则使用process_srv_queue重新进入proxy queue。 如果状态是SI_ST_EST，说明连接建立成功，使用sess_establish初始化一些参数。 resync_stream_interface 作为子分支存在，主要用于检测连接可用性。 if (unlikely(si_f-&gt;state == SI_ST_DIS)) si_f-&gt;state = SI_ST_CLO; if (unlikely(si_b-&gt;state == SI_ST_DIS)) { si_b-&gt;state = SI_ST_CLO; srv = objt_server(s-&gt;target); if (srv) { if (s-&gt;flags &amp; SF_CURR_SESS) { s-&gt;flags &amp;= ~SF_CURR_SESS; srv-&gt;cur_sess--; } sess_change_server(s, NULL); if (may_dequeue_tasks(srv, s-&gt;be)) process_srv_queue(srv); } } may_dequeue_tasks 用于判断是否有必要开始下个连接 s-&gt;nbpend 等待处理的连接数 srv_is_usable 是否有可用的服务器 maxconn 最大连接数等 process_srv_queue 检测proxy queue的是否有正在等待处理的连接，并将它们全部唤醒。 resync_request 用于分析请求，主要函数 tcp_inspect_request http_wait_for_request http_wait_for_request_body http_process_req_common process_switching_rules tcp_inspect_request http_process_req_common process_server_rules http_process_request process_sticking_rules http_request_forward_body resync_response tcp_inspect_response http_wait_for_response process_store_rules http_process_res_common http_response_forward_body ","tags":[{"index":-1,"name":"haproxy","slug":"haproxy","used":true,"link":"https://blog.xwl.io/tag/haproxy/"}],"title":"haproxy源码阅读（二）处理任务流程","feature":"","link":"https://blog.xwl.io/post/TZUaQzhYM/","stats":{"text":"4 min read","time":239000,"words":852,"minutes":4},"date":"2021-04-16 23:45:38","dateFormat":"2021-04-16"},{"content":" 所有源码分析基于haproxy version 1.6.14 首先分析核心代码haproxy.c /* Runs the polling loop */ void run_poll_loop() { int next; tv_update_date(0,1); while (1) { /* Process a few tasks */ process_runnable_tasks(); /* check if we caught some signals and process them */ signal_process_queue(); /* Check if we can expire some tasks */ next = wake_expired_tasks(); /* stop when there's nothing left to do */ if (jobs == 0) break; /* expire immediately if events are pending */ if (fd_cache_num || tasks_run_queue || signal_queue_len || applets_active_queue) next = now_ms; /* The poller will ensure it returns around &lt;next&gt; */ cur_poller.poll(&amp;cur_poller, next); fd_process_cached_events(); applet_run_active(); } } 简要说明 process_runnable_tasks 处理可运行的任务 signal_process_queue 处理信号队列，如果捕获了信号则需要处理 wake_expired_tasks 处理超时任务 cur_poller.poll 更新fd事件到缓存 fd_process_cached_events 处理fd事件 函数分析 整体描述下函数的作用 process_runnable_tasks 取出队列中的任务，调用process_stream函数处理，返回之后重新将task放入等待队列 主要任务 根据预设的规则设置一个backend process_switching_rules -&gt; stream_set_backend 根据相应的调度算法，选择后端服务器，并添加到队列中 sess_prepare_conn_req -&gt; srv_redispatch_connect -&gt; assign_server_and_queue -&gt; assign_server -&gt; chash_get_next_server 后端服务器请求已满，添加到proxy队列 pendconn_add signal_process_queue 自身实现的信号处理机制，接收到信号之后输出到队列，然后在处理信号队列，保证所有请求处理完之后再关闭 wake_expired_tasks 唤醒超时任务，队列分为run queue／wait queue，该函数就是检查wait queue任务，并将其输出到run queue中，以便后续处理。 cur_poller.poll 获取所有活动的fd，并将其更新到cache中 主要函数 _do_poll epoll_wait fd_may_recv fd_may_send fd_update_cache fd_process_cached_events 处理fd事件，建立连接、数据收发等 主要函数 conn_fd_handler si_conn_recv_cb raw_sock_to_pipe/ssl_sock_to_buf raw_sock_to_buf si_conn_send_cb ","tags":[{"index":-1,"name":"haproxy","slug":"haproxy","used":true,"link":"https://blog.xwl.io/tag/haproxy/"}],"title":"haproxy源码阅读（一）主循环流程","feature":"","link":"https://blog.xwl.io/post/s5EVafZW4/","stats":{"text":"2 min read","time":105000,"words":408,"minutes":2},"date":"2021-04-15 23:39:58","dateFormat":"2021-04-15"},{"content":"基础环境配置 mac环境下，自带的是clang，在编辑haproxy的时候会出现一系列的warning，所以先安装下gcc，haproxy官方测试通过的只有4.x版本 brew install gcc@4.9 然后修改haproxy的Makefile，120行。 CC = /usr/local/Cellar/gcc\\@4.9/4.9.4_1/bin/gcc-4.9 编译安装 make TARGET=osx make install PREFIX=/opt/haproxy vscode 配置 tasks.json { &quot;version&quot;: &quot;2.0.0&quot;, &quot;tasks&quot;: [ { &quot;label&quot;: &quot;haproxy&quot;, &quot;type&quot;: &quot;shell&quot;, &quot;command&quot;: &quot;sudo make TARGET=osx &amp;&amp; sudo make install PREFIX=/opt/haproxy &amp;&amp; sudo make clean&quot;, &quot;problemMatcher&quot;: [ &quot;$gcc&quot; ] } ] } 此时运行任务的时候就自动执行tasks.json的任务，进行编译，完成之后就能顺利调试。 launch.json { &quot;version&quot;: &quot;0.2.0&quot;, &quot;configurations&quot;: [ { &quot;name&quot;: &quot;(gdb) Launch&quot;, &quot;type&quot;: &quot;cppdbg&quot;, &quot;request&quot;: &quot;launch&quot;, &quot;program&quot;: &quot;/opt/haproxy/sbin/haproxy&quot;, &quot;args&quot;: [&quot;-f&quot;, &quot;/opt/haproxy/etc/haproxy.cfg&quot;], &quot;stopAtEntry&quot;: false, &quot;cwd&quot;: &quot;${workspaceFolder}&quot;, &quot;environment&quot;: [], &quot;externalConsole&quot;: false, &quot;MIMode&quot;: &quot;lldb&quot; } ] } 这个配置是用于调试环境下的，执行二进制程序环境的命令，以及使用的调试工具gdb/lldb。 ","tags":[{"index":-1,"name":"haproxy","slug":"haproxy","used":true,"link":"https://blog.xwl.io/tag/haproxy/"}],"title":"使用vscode调试haproxy","feature":"","link":"https://blog.xwl.io/post/tS0UUUJy6/","stats":{"text":"2 min read","time":87000,"words":290,"minutes":2},"date":"2021-04-15 23:29:08","dateFormat":"2021-04-15"},{"content":" 孙圈圈，移动学习品牌“圈外同学” 创始人兼CEO，领英洞察、36Kr专栏作家，毕业于南京大学经济学系，曾担任美世咨询（全球最大的人力资源管理咨询公司）总监，为多家国内外知名企业服务，设计组织架构和人才发展体系，著有职场类畅销书《请停止无效努力:如何用正确的方法快速进阶》。 一、 看人很准的我，栽在实习生手上 我曾经是一名管理咨询顾问，从事咨询工作8年多，当时我主要的工作职责是帮公司制定他们的人才发展战略，同时研究什么样特质的人适合做什么样的岗位。 所以我的工作中有一部分是看人。 一些大公司在选拔高管继任者的时候，会找到我们，我会花几个小时跟候选人相处，评估他们各方面的能力，看是否符合岗位要求。 这些企业高管的候选人，往往是中年男性，他们成熟、世故、善于伪装，“宁愿相信世界上有鬼，也别相信中年男人那张嘴”。 所以在这种训练下，我一直认为，自己看人很准，直到有一次，“栽”到了实习生手上。 那时候，我有两个实习生，其中一个男生，聪明、理性、在复旦念书，而另一个女生，学校一般、面试表现一般。各位，如果你们是我，你会看好哪一个呢？我跟大多数人一样，看好前面一个，也着力培养。 几个月之后，我让他们同时帮我写一份项目建议书，男生做得不错，分析详细、逻辑严密。 但是给我惊喜的却是这个女生，报告非常有洞见，她甚至利用社交网络去找了行业内部人士做了访谈。为什么几个月会发生反转呢？ 我百思不得其解，跟一个前辈聊起这个问题，她问我两个实习生的工作态度、我在他们身上花的时间、他们做的事情有无差异等等，最后她问到：两个小朋友的职业目标是什么？ 那一刻我突然恍然大悟，我想起自己曾经跟他们聊过“野心”这个话题。 男生说，他的野心是成为跨国公司CEO、做一个出色的职业经理人，所以他再晚也会做完我分配的工作。 但是都会按照我给的步骤去做，不会过于激进地创新，因为他不敢犯错。 而女生呢，会问我“如果我5年后要创立自己的公司，现在做咨询合适吗？”可我甚至还没有决定是否要留下她呢！ 她常常跟我要求一些能力以外的事情去做，还会尝试一些她认为可行的方法，有时候做成，也有时候搞砸，虽然给人不稳定的感觉，但这么一来，她的确成长却更快了。 从那以后，我在选人用人的时候，我会额外关注一个人的野心，也就是他做事的动力。 二、 动力不是驱动我们享受的，而是驱动我们付出的 我有必要解释一下，这里的动力是什么含义。可能很多人说：动力，就是自己喜欢或者想要的东西。 那么在座各位，你喜欢什么呢？ 我曾经问过很多人这个问题，得到的回答基本是：睡觉睡到自然醒，数钱数到手抽筋，工作地点离家近…… Ok，这些不是动力，也不是野心，那是什么呢？ 这些是人性本能。 那什么是动力呢？人类历史上1953年第一次登上珠峰，但在1924年，就有人几乎登上过，这个人叫乔治马洛里。 剑桥大学毕业，凯恩斯的同学加好友，有一个非常恩爱的妻子，最重要的是，颜值超高！简直是人生赢家！我们都想成为他这样的人，不是吗？ 但是他却多次冒着生命危险登珠峰，那可是在100年前，人类没有去过珠峰，所以没有地图，那时候没有羽绒服，更不用提高原反应。 实际上，马洛里在第二次尝试的时候，就因为雪崩，眼睁睁看着7个队友丧生，但他还是去了第三次。 然后在离山顶只有几百米的地方，他永远留在了那里，直到几十年后，人们发现了他的尸体。 记者曾经问他为什么，他说“Because it’s there”，就是那句著名的“因为，山就在那里”。 所谓本能，就是明知道一些事是对的，但是自己做不到；而所谓动力，就是我们能够反本能地去做到那些事情。 怕冷、怕死、怕累，是出于本能；而克服这些“怕”去爬珠峰，是出于动力。所以，动力不是让我们享受的，恰恰相反，是让我们甘愿付出的。 三、 成功者的共性是动力 这种动力，到底有多重要呢？ 我曾经跟之前的同事一起，给过去服务过的企业高管和个人客户做了个数据分析，分析对象都是各大企业的成功领导者。 在这些人当中，各个跟领导力相关的能力项，几乎都可以找到反面的例子，比如有人战略思维欠缺，有人团队管理方面不够成熟，但也能成为成功领导者。 可是，几乎没有人缺乏passion for success（也就是追求成功的热情）这一项。 为什么动力会如此重要呢？它在我们的发展过程中，起到什么样的作用呢？ 相信大家都听说过冰山模型，是美国著名心理学家麦克利兰提出来的，它全面地描述了一个人的个体素质要素。 一条海平面把冰山分成了上下两部分。 海平面上面的部分，是知识、技能和能力，解决了一个人“能不能”做某件事情；而天赋特性包括价值观、性格特质等等，解决了一个人“愿不愿”做某件事情。 这三类要素是自下而上逐渐影响的，底层要素决定了上层，比如我们有动力学习，然后才有学习能力的提升，然后有了学习能力，也能学会更多知识。 根据研究，冰山底层的要素中，光个性特质就能够解释员工绩效差异的35%，而冰山底层的因素加起来差不多决定了一个人的70%。 并且越往底层的要素越难被我们发现，同时也越难被改变，比如个性特质，基本在成年之后就达到稳定状态，除非遭遇重大的人生变故。 所以，如果我们所做的事情，跟自己冰山下面的要素相违背，相当于我们用10分的努力，最多得到3分的结果；而另一个人，只要选对了事情，他可能就有7分了。 找到我们的动力，就是如此重要。 四、 大部分人的问题，是野心配不上才华 我们经常听说这样一句话，“要让才华配得上自己的野心”。 可现实情况其实恰恰相反，大部分人的野心，其实是配不上才华的。 因为，才华是能力，而野心是动力，我们花了很多时间提升自己，可却不知道为什么。 野心配不上才华会如何呢？我不知道各位有没有过这种时刻，反正大部分我都有过： 高考之前以分数为目标，被家长推着走，大学的时候跟同学混着走，4年毕业之后，突然面临一个问题“我要做什么工作”，于是彻底懵逼； 之后，找到一份不喜欢也不讨厌的工作，拿着一份不高也不低的工资，想要做点什么来改变，可不知道怎么改变； 然后，因为不知道要做什么，所以就到处找事做，办了健身卡、买了知识付费产品、打算考几个证，也的确学到了一些东西，但是都没坚持下去。 最后放弃了折腾，安慰自己说“可能人生就是这样吧”，对很多事情都没有了热情，除了刷抖音的时候。 这些问题背后，可能就是野心配不上才华。当然，我们大多数人如何概括这种现象呢？统称两个字：迷茫。 所以，如果我们去问一个年轻人：你迷茫吗？他多半会回答说：哎？你怎么知道？ 我当然知道，我们都迷茫嘛！ 所以，找到我们的野心，让它对得起我们的才华和努力！ 五、 这个方法，帮我找到了野心，改变了我的人生轨迹 如何才能找到呢？ 在我快30岁的时候，我成为了公司晋升最快的咨询顾问，而且如果继续待下去，可能会成为这里最年轻的合伙人。 但是，突然某一天，我不想继续了。 咨询公司或者说所有的大公司，都有一个非常清晰的职业发展通道，好像一把梯子，只要我上了梯子、往上爬一格，就会有人给我加油、有人跟我竞争、有人给我鲜花和掌声。 然后在那种氛围下，我竭尽全力一直往上爬，这些给了我很强的外部动力，让我待了8年。 可是，当我快爬到顶的时候，我看到了梯子最顶端的风景，我突然发现那不是我想要的。我不要在这儿玩儿了，可我要什么，我不知道。 于是，我开始自我治疗，当时跟很多人聊过，也找了很多资料，结合了很多方法，最终真的找到了一个方法，让我找到了自己的野心，也改变了我的人生轨迹。 后来我分享过给很多人，也改变了他们。今天，我分享给你们。 第一步，我停了下来，开始回忆自己过去8年，回忆自己特别兴奋或者厌恶的时刻。也就是，回忆过去这些年的巅峰体验。 为什么要回忆体验呢？很简单，我们的野心本身就来源于感觉。 比如，有人会说自己想赚一个亿，但钱并不是我们真正追求的东西，我们想要钱，是看中了背后的安全感，还是给了家人团聚的可能，还是证明自己成功呢？ 这背后的感觉，才是我们要找的。 第二步，我找了10个朋友，都是跟我非常亲近的朋友，问他们，我在做什么事情的时候最专注、最热情、两眼放光。 为什么要找朋友呢？因为我们看自己的很多行为往往觉得理所当然、习以为常，但是我们的朋友，他们会从旁观者的角度来告诉我们真相。 那些你觉得理所当然可别人觉得匪夷所思的事情，可能就是你的热情所在。 之后，我找了一个周末的下午，把自己关在房间里面，面前铺开一大叠纸，开始一个个写自己想要做到的事情，就这样写了100多个。 人生几十年，我第一次知道自己这么贪心，想要得这么多。在写的过程中，大概有五六个，都曾经让我心潮澎湃。 然后，看着这五六条，我再一个个删。 我告诉自己：删掉，就意味着我这辈子不可能实现它了。这个过程中，我从刚才的极度兴奋变成极度崩溃。 最后，一张纸上留下了最后一条。 那一条是：影响并帮助他人成长。 想象我不去服务企业，而是我能够把自己的专业知识和经验输出，直接帮助一个人，我就觉得无比兴奋！ 所以，做完最后这一步，找到野心之后，再去找到能够满足我们野心的事情就可以了。 于是，在那天下午之后的几个月，我就从咨询公司辞职了，开始创业，做一家帮助年轻人成长的公司（注：圈外同学）。 我很庆幸当时自己找到了我要的答案。 六、 我找到了野心，但我又输掉了它 但是，故事还没结束，后来我跟团队一起，做了一件更加刺激的事情。 我们差不多10几个人，把我们的野心放在一起，除了我上面说的那条之外，还有一些很吸引人的。 比如找到相伴一生的灵魂伴侣，比如能够流芳百世，比如永远美丽动人，等等。 然后我们做了一个野心拍卖会，每个人分到10个筹码，拍自己要的那个东西，这些筹码代表的是自己拥有的时间。 轮到我的拍品的时候，我先叫了1个筹码，然后有人叫到2，很明显，另一个人也想要这个，然后我叫3的时候，她没有叫4，而是直接10个筹码all in了。 我一下子蒙了，那是我最想要的东西，可它现在属于别人，我觉得自己快要哭出来了。 回顾刚才的拍卖过程，我明明知道那是我唯一想要的东西，我应该做的是10个筹码all in。 但是我觉得，有10个筹码嘛，说不定可以用几个拍到自己最想要的，然后剩一些来拍其他物品，毕竟那些也都很有吸引力啊！ 可当有人all in的时候，我输掉了。 这像极了我们的现实人生，很多时候，我们明明有自己内心想要的东西，但是当我们看到同学、朋友、亲戚手里的其他东西，又觉得“哎，好像也不错”。 非常羡慕他们，会想是不是也可以去试试，但最后，我们疲于奔命、什么也没有得到。 后来在我创业过程中，面临过很多次困境，也面临过很多诱惑，但每当这个时候，我就会想起拍卖会上，我失去野心的那种痛苦，然后我总能更容易地做出选择。 回到刚开始那两个实习生的故事，他们现在发展得都不错，男生在一家500强公司，而女生呢，现在在我们创业团队，而且她就是那个在拍卖会上跟我抢野心的人。 他们的野心和才华，都得到了最好的安排。 所以各位，我今天特别想分享这个观点：花一点时间，去找到自己的野心，然后聚焦，让它配得上我们的才华！ 我们都以为，那种所谓“野心”都离我们太远了，只有那些改变世界的人，比如乔布斯，才配得上谈野心。 但是，我们所有人都有属于自己的野心。 它并不是一个所有人都一致的东西，无论我们的野心是“改变世界”还是“家庭美满”，都是有价值的。 因为，它会让我们专注于自己的需求，让我们不再抱怨这样那样的不顺心，不再纠结这样那样的选择，不再羡慕别人有这样那样的东西。 我们的人生就像那座冰山，海平面上会有无数狂风暴雨，但只要找到了自己的野心，我们就能在海平面底下安然无恙。 所以，找到我们的野心，让它配得上我们的才华！ ","tags":[{"index":0,"name":"个人成长","slug":"personal-growth","used":true,"link":"https://blog.xwl.io/tag/personal-growth/"}],"title":"别让我们的野心配不上才华｜圈圈@TEDx","feature":"","link":"https://blog.xwl.io/post/sMLLztYXw/","stats":{"text":"14 min read","time":819000,"words":4063,"minutes":14},"date":"2021-04-13 21:51:05","dateFormat":"2021-04-13"},{"content":"简介 本站基于Gridea构建 也曾折腾过Wordpress、Ghost、Hexo、Hugo等博客，在来回迁移的痛苦中，却没有多少文章产出。 但请不要忘记初心❤️ 主流开源博客对比 Wordpress：什么都有，唯一的毛病都是慢。 Ghost：生态不错，但考虑到国内的网络环境和本地化程度，只适合做英文站。 Hexo：折腾型选手，缺点是文章过多编译时太慢。 Hugo：折腾型选手，编译效率上去了，但是写文章体验不是很好。 Gridea：有独立客户端，几乎没有生态，但用起来很方便，适合专注创作的朋友。 Gridea的同步问题 经常因为网络问题，出现同步失败的情况，是因为GitHub被墙的缘故，使用Ping工具去检查一下，然后找个延迟低的IP地址，替换一下Host即可。 本站构建使用的模块 以下是我现在使用的一些组件，给大家省点时间。 网站部署 GitHub Page + Cloudflare 客户端 Gridea 模版 Gridea-theme-Chic 评论系统 Valine + Leancloud 邮件订阅入口 Tinyletter ","tags":[{"index":-1,"name":"未归档","slug":"undefined","used":true,"link":"https://blog.xwl.io/tag/undefined/"}],"title":"关于本站服务构建","feature":"","link":"https://blog.xwl.io/post/5wRgq8uqf/","stats":{"text":"2 min read","time":61000,"words":286,"minutes":2},"date":"2021-04-01 01:20:49","dateFormat":"2021-04-01"}]}